defaults: &defaults
  docker:
    - image: docker.io/stackrox/apollo-ci:0.1.11-24-gbcb6b87a51
      auth:
        username: $DOCKER_IO_USERNAME
        password: $DOCKER_IO_PASSWORD
  working_directory: /go/src/github.com/stackrox/rox

setupBazel: &setupBazel
  run:
    name: Setup Bazel cache access and bazel.rc
    command: |
      echo "$GKE_SERVICE_ACCOUNT" > /tmp/gcp.json
      cp tools/ci-bazel.rc .bazelrc

depCacheKey: &depCacheKey 'v1-rox-go-pkg-dep-{{ checksum "Gopkg.lock" }}'
restoreDep: &restoreDep
  restore_cache:
    keys:
      - *depCacheKey
      - v1-rox-go-pkg-dep

gradleCacheKey: &gradleCacheKey 'v1-rox-gradle-{{ checksum "qa-tests-backend/build.gradle" }}'
restoreGradle: &restoreGradle
  restore_cache:
    keys:
      - *gradleCacheKey
      - v1-rox-gradle

uiCacheKey: &uiCacheKey 'v1-rox-ui-deps-{{ checksum "ui/yarn.lock" }}'
restoreUI: &restoreUI
  restore_cache:
    keys:
      - *uiCacheKey
      - v1-rox-ui-deps

setupHelm: &setupHelm
  run:
    name: Setup tiller by default in GKE Cluster
    command:  |
       kubectl apply -f ./deploy/k8s/tillerbind.yaml

       SUCCESS=0
       for i in {1..10}; do
         if helm init --service-account helm  --tiller-connection-timeout 5 --wait; then
           SUCCESS=1
           break
         fi
         echo "Failed to connect to helm. Retrying in 5 seconds"
         sleep 5
         kubectl -n kube-system get pod
       done

       if [[ "${SUCCESS}" -eq 0 ]]; then
         echo "Failed to connect to helm"
         exit 1
       fi

refreshAlpineBaseImage: &refreshAlpineBaseImage
  run:
    name: Refresh base image
    command: docker pull alpine:3.9


setupRoxctl: &setupRoxctl
  run:
    name: Setup Roxctl from bazel-bin
    command: |
      cp bazel-bin/roxctl/linux_amd64_pure_stripped/roxctl $GOPATH/bin/roxctl

setupGCP: &setupGCP
  run:
    name: Setup deployment env
    command: |
      docker login -u "$DOCKER_IO_USERNAME" -p "$DOCKER_IO_PASSWORD"
      cat >>"$BASH_ENV" <<EOF
        export REGISTRY_USERNAME="$DOCKER_IO_USERNAME"
        export REGISTRY_PASSWORD="$DOCKER_IO_PASSWORD"
        export MAIN_IMAGE_TAG="$(make tag)"
        export GOOGLE_APPLICATION_CREDENTIALS=/tmp/gcp.json
      EOF
      if .circleci/pr_has_label.sh ci-run-against-rhel; then
        echo 'export MAIN_IMAGE_REPO=stackrox/main-rhel' >> "${BASH_ENV}"
      fi

      echo $GKE_SERVICE_ACCOUNT > /tmp/gcp.json
      gcloud auth activate-service-account --key-file /tmp/gcp.json
      gcloud config set project stackrox-ci
      gcloud config set compute/region us-central1
      gcloud config unset compute/zone
      gcloud config set core/disable_prompts True

createGKE: &createGKE
  run:
    name: Create GKE cluster
    command: |
      source .circleci/create-cluster.sh && create-cluster

# See https://stackoverflow.com/a/46316672 for why we have to use user/pass.
# This step requires the GCP IAM permission "Kubernetes Engine Admin".
deployGKE: &deployGKE
  run:
    name: Deploy to remote cluster
    command: |
      kubectl create clusterrolebinding temporary-admin --clusterrole=cluster-admin --user circleci-gke@ultra-current-825.iam.gserviceaccount.com
      ./deploy/k8s/deploy.sh
      kubectl delete clusterrolebinding temporary-admin

      source ./scripts/k8s/export-basic-auth-creds.sh ./deploy/k8s/
      cat >>"$BASH_ENV" <<EOF
        export ROX_USERNAME="$ROX_USERNAME"
        export ROX_PASSWORD="$ROX_PASSWORD"
      EOF

setupCIMonitoring: &setupCIMonitoring
  run:
    name: Set up CI monitoring
    command: |
      [[ -n "$INFLUXDB_URL" ]] || exit 0
      cd ci-monitoring
      export CIRCLE_PR_NUMBER="${CIRCLE_PR_NUMBER:-none}"
      envsubst <telegraf.conf.template >telegraf.conf
      envsubst <monitoring.yaml.template >monitoring.yaml
      kubectl -n stackrox create secret generic influxdb-ci-proxy-config --from-file=./telegraf.conf
      kubectl -n stackrox replace --force -f ./monitoring.yaml

      echo "Set up CI monitoring to write to ${INFLUXDB_URL}."

waitForAPI: &waitForAPI
  run:
    name: Wait for the API server to be up
    command: |
      export API_HOSTNAME=localhost
      export API_PORT=8000
      if [[ "${LOAD_BALANCER}" == "lb" ]]; then
        export API_HOSTNAME=$(./scripts/k8s/get-lb-ip.sh)
        export API_PORT=443
      fi
      export PING_URL="https://${API_HOSTNAME}:${API_PORT}/v1/ping"
      echo "PING_URL is set to ${PING_URL}"
      set +e
      SUCCESS=0
      for i in $(seq 1 25); do
        if [[ "$(curl -sk --connect-timeout 5 --max-time 10 "${PING_URL}" | jq '.status' -r)" == "ok" ]]; then
          SUCCESS=1
          break
        fi
        sleep 5
      done
      if [[ "${SUCCESS}" == 0 ]]; then
        kubectl -n stackrox get pod
        echo "Failed to connect to Central"
        exit 1
      fi
      cat >>"$BASH_ENV" <<EOF
        export API_HOSTNAME="$API_HOSTNAME"
        export API_PORT="$API_PORT"
        export API_ENDPOINT="${API_HOSTNAME}:${API_PORT}"
      EOF

waitForSensorK8s: &waitForSensorK8s
  run:
    name: Wait for the Sensor to be running K8s
    command: |
      ./scripts/ci/sensor-wait.sh

determineWhetherToRunUIDevServer: &determineWhetherToRunUIDevServer
  run:
    name: Determine whether to run the UI dev server
    command: |
      if .circleci/pr_has_label.sh ci-ui-dev-server; then
        echo "Running UI E2Es against the dev server due to the presence of the ci-ui-dev-server label."
        echo 'export RUN_UI_DEV_SERVER=true' >> "${BASH_ENV}"
      else
        echo "Running UI E2Es against the production server. Apply the ci-ui-dev-server label to your PR to run against the dev server."
        echo 'export RUN_UI_DEV_SERVER=false' >> "${BASH_ENV}"
      fi

runUIDevServer: &runUIDevServer
  run:
    name: Run the UI dev server
    command: |
      if [ "${RUN_UI_DEV_SERVER}" = "true" ]; then
        make -C ui start
      fi
    background: true

waitForUIDevServer: &waitForUIDevServer
  run:
    name: Wait for the UI dev server to be up
    command: |
      if [ "${RUN_UI_DEV_SERVER}" = "true" ]; then
        curl -k --max-time 60 --retry 50 --retry-connrefused --retry-delay 5 --retry-max-time 300 https://127.0.0.1:3000/v1/ping
      else
        echo "Not running the dev server, skipping..."
      fi

runUIE2E: &runUIE2E
  run:
    name: UI e2e tests
    command: |
      if [ "${RUN_UI_DEV_SERVER}" = "true" ]; then
        export UI_BASE_URL="https://localhost:3000"
      else
        if [[ "${LOAD_BALANCER}" == "lb" ]]; then
          LB_IP=$(./scripts/k8s/get-lb-ip.sh)
          sudo sh -c "echo >>/etc/hosts ${LB_IP} central-lb"
          export UI_BASE_URL="https://central-lb:443"
        else
          export UI_BASE_URL="https://localhost:8000"
          ./scripts/port-forward-ui.sh
        fi
      fi

      make -C ui test-e2e-ci

collectImbuedUILogs: &collectImbuedUILogs
  run:
    name: Collect imbued UI logs
    command: |
      mkdir -p /tmp/imbued-ui-logs
      curl_cmd=(curl)
      if [[ -n "$ROX_USERNAME" && -n "$ROX_PASSWORD" ]]; then
        curl_cmd+=(-u "${ROX_USERNAME}:${ROX_PASSWORD}")
      fi
      status_code="$("${curl_cmd[@]}" -sk -o logs.zip -w "%{http_code}\n" "https://${API_ENDPOINT}/api/logimbue")"
      # Central returns 204 if there are no imbued logs
      if [ "${status_code}" -eq 204 ]; then
        echo "No imbued logs found."
      elif [ "${status_code}" -eq 200 ]; then
        echo "Logs imbued from the UI were found. Please find them in the artifacts section."
        unzip logs.zip -d /tmp/imbued-ui-logs
      else
        echo "Received error status code ${status_code} from the log imbue endpoint; is the log imbue handler broken?"
        exit 1
      fi
    when:
      always

storeImbuedUILogs: &storeImbuedUILogs
  store_artifacts:
    path: /tmp/imbued-ui-logs
    destination: imbued-ui-logs


teardownGKE: &teardownGKE
  run:
    name: Tear down GKE cluster
    command: |
      gcloud container clusters delete "prevent-ci-${CIRCLE_BUILD_NUM}" --async
    when: always

collectK8sLogs: &collectK8sLogs
  run:
    name: Collect k8s logs
    command: |
      set +e
      ./scripts/ci/collect-service-logs.sh central deployment
      ./scripts/ci/collect-service-logs.sh monitoring deployment
      ./scripts/ci/collect-service-logs.sh sensor deployment
      ./scripts/ci/collect-service-logs.sh scanner deployment
      ./scripts/ci/collect-service-logs.sh collector daemonset
    when: always

storeK8sLogs: &storeK8sLogs
  store_artifacts:
    path: /tmp/k8s-service-logs
    destination: k8s-service-logs

storeProfilingResults: &storeProfilingResults
  store_artifacts:
    path: /tmp/pprof
    destination: pprof

storeCypressResults: &storeCypressResults
 store_test_results:
    path: ui/cypress/reports

storeCypressVideos: &storeCypressVideos
  store_artifacts:
    path: ui/cypress/videos
    destination: ui-e2e-videos

storeCypressScreenshots: &storeCypressScreenshots
  store_artifacts:
    path: ui/cypress/screenshots
    destination: ui-e2e-screenshots

storeQATestResults: &storeQATestResults
  store_test_results:
    path: qa-tests-backend/build/test-results/test

storeQASpockReports: &storeQASpockReports
  store_artifacts:
    path: ./qa-tests-backend/build/spock-reports
    destination: qa-test-report

checkOpenshiftLabel: &checkOpenshiftLabel
  run:
    name: Determine whether to run OpenShift tests
    command: |
      set +e
      .circleci/pr_has_label.sh ci-openshift-tests
      if [ $? -eq 1 ]; then
        echo "Skipping tests because we're on a PR. Apply the ci-openshift-tests label to your PR if you want to run them."
        circleci step halt
      fi

checkScaleLabel: &checkScaleLabel
  run:
    name: Determine whether to run Scale tests
    command: |
      set +e
      .circleci/pr_has_label.sh ci-scale-tests
      if [ $? -eq 1 ]; then
        echo "Skipping tests because we're on a PR. Apply the ci-scale-tests label to your PR if you want to run them."
        circleci step halt
      fi

version: 2
jobs:

  pre-build-ui:
    <<: *defaults
    resource_class: large
    steps:
      - checkout
      - *restoreUI
      - run:
          name: Build UI
          command: make -C ui build

      - save-cache:
          key: *uiCacheKey
          paths:
            - ui/node_modules
            - ~/.cache/Cypress # Cypress binary will be put there, see https://docs.cypress.io/guides/guides/continuous-integration.html#Example-circle-yml-v2-config-file-with-yarn

      - persist_to_workspace:
          root: /go/src/github.com/stackrox/rox
          paths:
            - ui/build # Copied directly into the image downstream.
            - ui/deps

  pre-build-cli:
    <<: *defaults
    resource_class: large
    steps:
      - checkout
      - *restoreDep
      - *setupBazel
      - run:
          name: Build the CLI
          command: make cli

      - save-cache:
          key: *depCacheKey
          paths:
            - /go/pkg/dep

      - persist_to_workspace:
          root: /go/src/github.com/stackrox/rox
          paths:
            - bazel-bin/roxctl/linux_amd64_pure_stripped/roxctl
            - bazel-bin/roxctl/darwin_amd64_pure_stripped/roxctl
            - bazel-bin/roxctl/windows_amd64_pure_stripped/roxctl.exe

  pre-build-go-binaries:
    <<: *defaults
    resource_class: large
    steps:
      - checkout
      - *restoreDep
      - *setupBazel

      - run:
          name: Build the main Go binaries
          command: make main-build

      - run:
          name: Generate the swagger docs
          command: make swagger-docs

      - run:
          name: Install ossls
          working_directory: /tmp
          command: |
            wget --quiet https://github.com/gruntwork-io/fetch/releases/download/v0.3.2/fetch_linux_amd64
            sudo install fetch_linux_amd64 /usr/bin/fetch
            export GITHUB_OAUTH_TOKEN="$GITHUB_TOKEN"
            fetch --repo="https://github.com/stackrox/ossls" --tag="0.3.0-rc1" --release-asset="ossls_linux_amd64" .
            sudo install ossls_linux_amd64 /usr/bin/ossls
            ossls -version

      - run:
          name: Generate OSS notice
          command: make ossls-notice

      - persist_to_workspace:
          root: /go/src/github.com/stackrox/rox
          paths:
            - bazel-bin/central/linux_amd64_pure_stripped/central
            - bazel-bin/migrator/linux_amd64_pure_stripped/migrator
            - bazel-bin/sensor/kubernetes/linux_amd64_pure_stripped/kubernetes
            - bazel-bin/compliance/collection/linux_amd64_pure_stripped/collection
            - image/NOTICE.txt # Required license notice
            - image/docs # This will go into the image as generated docs.
            - deps # Used to speed up k8s-tests
            - generated # Used to speed up k8s-tests
            - vendor # Used to speed up k8s-tests

  build:
    <<: *defaults
    resource_class: large
    steps:
      - checkout
      - setup_remote_docker

      - attach_workspace:
          at: /go/src/github.com/stackrox/rox

      - *refreshAlpineBaseImage

      - run:
          name: Build main image
          command: make docker-build-main-image

      - run:
          name: Push new Docker image
          command: |
            docker login -u $DOCKER_IO_USERNAME -p $DOCKER_IO_PASSWORD docker.io
            docker push "stackrox/main:$(make tag)" | cat

      - save-cache:
          key: *depCacheKey
          paths:
            - /go/pkg/dep

      - store_artifacts:
          path: bazel-bin/roxctl/linux_amd64_pure_stripped/roxctl
          destination: roxctl/roxctl-linux

      - store_artifacts:
          path: bazel-bin/roxctl/darwin_amd64_pure_stripped/roxctl
          destination: roxctl/roxctl-darwin

      - run:
          name: Comment on PR
          command: |
            wget --quiet https://github.com/joshdk/hub-comment/releases/download/0.1.0-rc6/hub-comment_linux_amd64
            sudo install hub-comment_linux_amd64 /usr/bin/hub-comment

            export TAG=$(make tag)
            hub-comment -template-file .circleci/comment-template.tpl

  build-rhel:
    <<: *defaults
    resource_class: large
    steps:
      - checkout
      - setup_remote_docker

      - attach_workspace:
          at: /go/src/github.com/stackrox/rox

      - run:
          name: Login to RedHat registry
          command: docker login -u "$REDHAT_REGISTRY_USERNAME" -p "$REDHAT_REGISTRY_PASSWORD" https://registry.redhat.io

      - run:
          name: Build main image for RHEL
          command: make docker-build-main-image-rhel

      - run:
          name: Push new image
          command: |
            docker login -u "$DOCKER_IO_USERNAME" -p "$DOCKER_IO_PASSWORD" docker.io

            TAG="$(make tag)"
            docker push "stackrox/main-rhel:${TAG}" | cat

  build-scale-monitoring-and-mock-server:
    <<: *defaults
    resource_class: large
    steps:
      - checkout
      - setup_remote_docker

      - *refreshAlpineBaseImage

      - *restoreDep
      - *setupBazel

      - run:
          name: Build images
          command: make scale-image mock-grpc-server-image monitoring-image

      - run:
          name: Push new Docker image
          command: |
            docker login -u $DOCKER_IO_USERNAME -p $DOCKER_IO_PASSWORD docker.io

            TAG=$(make tag)

            for img in scale grpc-server monitoring; do
              docker push "stackrox/${img}:${TAG}" | cat
            done

  unit-tests:
    <<: *defaults
    resource_class: large
    steps:
      - checkout

      - *restoreDep
      - *restoreGradle
      - *restoreUI

      - *setupBazel

      - run:
          name: Run Go unit tests
          command: make bazel-test

      - run:
          name: Run UI unit tests
          command: make ui-test

      - run:
          name: Upload coverage information
          command: make upload-coverage

  style-checks:
    <<: *defaults
    resource_class: large
    steps:
      - checkout

      - *restoreDep
      - *restoreGradle
      - *restoreUI

      - run:
          name: Run style checks
          command: make style

      - store_artifacts:
          path: qa-tests-backend/build/reports/codenarc
          destination: reports/codenarc

      - run:
          name: Ensure that generated files are up to date. (If this fails, run `make go-generated-srcs` and commit the result.)
          command: |
            make go-generated-srcs
            git diff --exit-code HEAD

  integration-unit-tests:
    <<: *defaults
    resource_class: large
    steps:
      - checkout
      - setup_remote_docker

      - *restoreDep
      - *restoreGradle
      - *restoreUI

      - *setupBazel

      - run:
          name: Run integration tests
          command: make integration-unit-tests

  k8s-tests:
    <<: *defaults
    environment:
      - MONITORING_SUPPORT: true
      - INFLUXDB_URL: "http://monitoring-1.us-central1-c.c.stackrox-ci.internal:8086"
      - LOAD_BALANCER: lb
    steps:
      - checkout

      - run:
          name: Determine whether to skip tests
          command: |
            if .circleci/pr_has_label.sh ci-no-k8s-tests; then
              echo "Skipping tests because of the presence of the ci-no-k8s-tests label..."
              circleci step halt
            fi

      - setup_remote_docker

      - attach_workspace:
          at: /go/src/github.com/stackrox/rox

      - *setupRoxctl
      - *setupGCP
      - *createGKE
      - *deployGKE
      - *setupCIMonitoring
      - *waitForAPI
      - *waitForSensorK8s

      - run:
          name: API tests
          command: |
            ./tests/yamls/roxctl_verification.sh
            make -C tests

      - *restoreUI
      - *determineWhetherToRunUIDevServer
      - *runUIDevServer
      - *waitForUIDevServer
      - *runUIE2E

      - *collectImbuedUILogs
      - *storeImbuedUILogs

      - *collectK8sLogs
      - *storeK8sLogs

      - *teardownGKE

      - *storeCypressResults
      - *storeCypressScreenshots
      - *storeCypressVideos

  qa-tests:
    <<: *defaults
    environment:
      - LOCAL_PORT: 443
      - RUNTIME_SUPPORT: true
      - MONITORING_SUPPORT: true
      - ROX_COMPLIANCE_ENABLED: true
      - ROX_PERFORM_DEPLOYMENT_RECONCILIATION: true
      - INFLUXDB_URL: "http://monitoring-1.us-central1-c.c.stackrox-ci.internal:8086"
      - LOAD_BALANCER: lb

    steps:
      - checkout

      - run:
          name: Determine whether to skip tests
          command: |
            if .circleci/pr_has_label.sh ci-no-qa-tests; then
              echo "Skipping tests because of the presence of the ci-no-qa-tests label..."
              circleci step halt
            fi

      - setup_remote_docker

      - attach_workspace:
          at: /go/src/github.com/stackrox/rox

      - *setupRoxctl
      - *setupGCP
      - *createGKE
      - *deployGKE
      - *setupCIMonitoring
      - *waitForAPI
      - *waitForSensorK8s

      - *restoreGradle
      - run:
          name: QA Automation Platform
          command: |
            export CLUSTER=K8S
            export HOSTNAME="${API_HOSTNAME}"
            export PORT="${API_PORT}"
            ./scripts/ci/create-webhookserver.sh kubectl
            if [ "${CIRCLE_BRANCH}" = "master" ]; then
              echo "On master, running all QA tests..."
              make -C qa-tests-backend test
            elif .circleci/pr_has_label.sh ci-all-qa-tests; then
              echo "ci-all-qa-tests label was specified, so running all QA tests..."
              make -C qa-tests-backend test
            else
              echo "On a PR branch, running BAT tests only..."
              make -C qa-tests-backend bat-test
            fi

      - save-cache:
          key: *gradleCacheKey
          paths:
          - ~/.gradle/caches/

      - *storeQATestResults
      - *storeQASpockReports

      - *collectK8sLogs
      - *storeK8sLogs

      - *teardownGKE

  qa-tests-cos-ebpf:
    <<: *defaults
    environment:
      - LOCAL_PORT: 443
      - RUNTIME_SUPPORT: true
      - MONITORING_SUPPORT: true
      - ROX_COMPLIANCE_ENABLED: true
      - ROX_COLLECTOR_EBPF: true
      - GCP_IMAGE_TYPE: "COS"
      - ROX_PERFORM_DEPLOYMENT_RECONCILIATION: true
      - INFLUXDB_URL: "http://monitoring-1.us-central1-c.c.stackrox-ci.internal:8086"
      - LOAD_BALANCER: lb

    steps:
      - checkout

      - run:
          name: Determine whether to skip tests
          command: |
            if .circleci/pr_has_label.sh ci-no-qa-tests; then
              echo "Skipping tests because of the presence of the ci-no-qa-tests label..."
              circleci step halt
            fi

      - setup_remote_docker

      - attach_workspace:
          at: /go/src/github.com/stackrox/rox

      - *setupRoxctl
      - *setupGCP
      - *createGKE
      - *deployGKE
      - *setupCIMonitoring
      - *waitForAPI
      - *waitForSensorK8s

      - *restoreGradle
      - run:
          name: QA Automation Platform
          command: |
            export CLUSTER=K8S
            export HOSTNAME="${API_HOSTNAME}"
            export PORT="${API_PORT}"
            if [ "${CIRCLE_BRANCH}" = "master" ]; then
              echo "On master, running all QA tests..."
              make -C qa-tests-backend test
            elif .circleci/pr_has_label.sh ci-all-qa-tests; then
              echo "ci-all-qa-tests label was specified, so running all QA tests..."
              make -C qa-tests-backend test
            else
              echo "On a PR branch, running RUNTIME tests only..."
              make -C qa-tests-backend runtime-test
            fi

      - save-cache:
          key: *gradleCacheKey
          paths:
          - ~/.gradle/caches/

      - *storeQATestResults
      - *storeQASpockReports

      - *collectK8sLogs
      - *storeK8sLogs

      - *teardownGKE

  upgrade-test:
    <<: *defaults
    environment:
      - STORAGE: pvc
      - LOAD_BALANCER: lb

    steps:
      - checkout
      - setup_remote_docker
      - attach_workspace:
          at: /go/src/github.com/stackrox/rox

      - *setupRoxctl
      - *setupGCP
      - *createGKE
      - run:
          name: Checkout 2.4.16.4
          command: git checkout 2.4.16.4
      - run:
          name: Launch Central only
          command: |
            cat >>"$BASH_ENV" <<EOF
              export MAIN_IMAGE_TAG="$(make tag)"
            EOF
            ./deploy/k8s/central.sh

            central_image="$(kubectl -n stackrox get deploy/central -o jsonpath='{.spec.template.spec.containers[?(@.name=="central")].image}')"
            if [ "${central_image}" != "stackrox/main:2.4.16.4" ]; then
              echo "Unexpected central image!"
              kubectl -n stackrox describe deploy/central
              exit 1
            fi

            source ./scripts/k8s/export-basic-auth-creds.sh ./deploy/k8s/
            cat >>"$BASH_ENV" <<EOF
              export ROX_USERNAME="$ROX_USERNAME"
              export ROX_PASSWORD="$ROX_PASSWORD"
            EOF
      - run:
          name: Checkout current commit again
          command: git reset --hard "${CIRCLE_SHA1}"

      - *waitForAPI
      - run:
          name: Restore DB
          command: |
            roxctl -e "${API_HOSTNAME}:${API_PORT}" -p "${ROX_PASSWORD}" central db restore \
              --file ./qa-tests-backend/artifacts/upgrade-tests/v2.4.16.4/stackrox_db_2019_03_01_03_48_45.zip
      - run:
          name: Do the upgrade
          command: |
            new_image="stackrox/main:$(make tag)"
            kubectl -n stackrox set image deploy/central central="${new_image}"
            kubectl -n stackrox describe deploy/central

            central_image="$(kubectl -n stackrox get deploy/central -o jsonpath='{.spec.template.spec.containers[?(@.name=="central")].image}')"
            if [ "${central_image}" != "${new_image}" ]; then
              echo "Unexpected central image!"
              exit 1
            fi
      - *restoreGradle

      - *waitForAPI
      - run:
          name: Run upgrade tests
          command: |
            export CLUSTER=K8S
            export HOSTNAME="${API_HOSTNAME}"
            export PORT="${API_PORT}"
            make -C qa-tests-backend upgrade-test

      - *storeQATestResults
      - *storeQASpockReports

      - *collectK8sLogs
      - *storeK8sLogs

      - *teardownGKE

  scale:
    <<: *defaults
    environment:
      - MONITORING_SUPPORT: true
      - INFLUXDB_URL: "http://monitoring-1.us-central1-c.c.stackrox-ci.internal:8086"
      - STORAGE: pvc
      - LOAD_BALANCER: lb
      - OUTPUT_FORMAT: helm

    steps:
      - checkout
      - *checkScaleLabel
      - setup_remote_docker
      - attach_workspace:
          at: /go/src/github.com/stackrox/rox

      - *setupRoxctl
      - *setupGCP
      - *createGKE
      - *setupHelm

      - run:
          name: Launch Central only
          command: |
            ./deploy/k8s/central.sh

            source ./scripts/k8s/export-basic-auth-creds.sh ./deploy/k8s/
            cat >>"$BASH_ENV" <<EOF
              export ROX_USERNAME="$ROX_USERNAME"
              export ROX_PASSWORD="$ROX_PASSWORD"
            EOF

      - *setupCIMonitoring
      - *waitForAPI

      - run:
          name: Launch Mock Sensors
          command: |
            ./scale/mocksensor/launch_multiple_mock_sensors.sh -instances=10 -max-deployments=200 -max-indicators=4000 -max-network-flows=20 -max-updates=2000
            mkdir /tmp/pprof
            ./scale/profiler/pprof.sh /tmp/pprof "${API_ENDPOINT}" 6
      - *storeProfilingResults

      # TODO(viswa): Figure out how to fix this.
      # - run:
      #    name: Delete all mock sensors
      #    command: kubectl -n stackrox delete deployments --selector "type=mocksensor"

      # - run:
      #    name: Launch da real sensor
      #    command: |
      #      kubectl create clusterrolebinding temporary-admin --clusterrole=cluster-admin --user circleci-gke@ultra-current-825.iam.gserviceaccount.com
      #      ./deploy/k8s/sensor.sh
      #      kubectl delete clusterrolebinding temporary-admin

      # - *waitForSensorK8s

      # - run:
      #    name: Kill our pods a few times
      #    command: ./scripts/ci/chaos_monkey.sh
      # - run:
      #    name: Restart port forward
      #    command: ./scripts/k8s/local-port-forward.sh
      #    background: true
      # - *waitForAPI
      # - *waitForSensorK8s
      # - *restoreGradle
      # - run:
      #    name: QA Automation Platform
      #    command: |
      #      export CLUSTER=K8S
      #      export HOSTNAME="${API_HOSTNAME}"
      #      export PORT="${API_PORT}"
      #      make -C qa-tests-backend smoke-test

      - *collectK8sLogs
      - *storeK8sLogs
      - *teardownGKE


  provision-openshift:
    machine: true
    environment:
      - OPENSHIFT_AUTOMATION_VERSION: 0.4.0
    steps:
      - checkout
      - *checkOpenshiftLabel

      - run:
          name: Login to Docker Hub
          command: docker login -u "$DOCKER_IO_USERNAME" -p "$DOCKER_IO_PASSWORD"

      - run:
          name: Install kubectl
          working_directory: /tmp
          command: |
            wget https://storage.googleapis.com/kubernetes-release/release/v1.11.2/bin/linux/amd64/kubectl
            sudo install kubectl /usr/bin

      - run:
          name: Generate ephemeral SSH key
          command: |
            mkdir -p openshift
            ssh-keygen -t rsa -f openshift/id_rsa -C packer -N ''
            chmod 0400 openshift/id_rsa openshift/id_rsa.pub
            cat openshift/id_rsa.pub

      - run:
          name: Create cloud resources
          command: |
            docker run --rm -t \
              -v $PWD/openshift:/data \
              -e GOOGLE_CREDENTIALS="$OPENSHIFT_TERRAFORM_CREDENTIALS" \
              stackrox/openshift-automation:terraform-$OPENSHIFT_AUTOMATION_VERSION create "${CIRCLE_SHA1:0:7}"

      - store_artifacts:
          path: openshift
          destination: openshift

      - run:
          name: Create Openshift cluster
          command: |
            docker run --rm -t \
            -v $PWD/openshift:/data \
            stackrox/openshift-automation:ansible-$OPENSHIFT_AUTOMATION_VERSION

      - run:
          name: Configure Kubeconfig
          command: |
            ls -lh $PWD/openshift
            export KUBECONFIG=$PWD/openshift/config
            kubectl get nodes

      - store_artifacts:
          path: openshift
          destination: openshift

      - persist_to_workspace:
          root: .
          paths:
            - openshift

      - run:
          name: Destroy Openshift cluster
          command: |
            docker run --rm -t \
              -v $PWD/openshift:/data \
              -e GOOGLE_CREDENTIALS="$OPENSHIFT_TERRAFORM_CREDENTIALS" \
              stackrox/openshift-automation:terraform-$OPENSHIFT_AUTOMATION_VERSION destroy "${CIRCLE_SHA1:0:7}"
          when: on_fail


  openshift-tests:
    <<: *defaults
    environment:
      - OPENSHIFT_AUTOMATION_VERSION: 0.4.0
      - LOCAL_PORT: 8000
      - RUNTIME_SUPPORT: true
      - MONITORING_SUPPORT: true
      - ROX_COMPLIANCE_ENABLED: true
      - INFLUXDB_URL: "https://influxdb.monitoring.ci.rox.systems"
      - ROX_PERFORM_DEPLOYMENT_RECONCILIATION: true

    steps:
      - checkout
      - *checkOpenshiftLabel
      - setup_remote_docker

      - run:
          name: Login to Docker Hub
          command: docker login -u "$DOCKER_IO_USERNAME" -p "$DOCKER_IO_PASSWORD"

      - attach_workspace:
          at: /go/src/github.com/stackrox/rox

      - run:
          name: Sanity check OpenShift Env
          command: |
            pwd
            ls -lh $PWD/openshift
            export KUBECONFIG=$PWD/openshift/config
            oc get nodes

      - *setupRoxctl

      - run:
          name: Configure Deployment Environment
          command: |
            cat >>"$BASH_ENV" <<EOF
              export KUBECONFIG=$PWD/openshift/config
              export CLAIRIFY_IMAGE_TAG=0.5.2
              export OPENSHIFT_HOST=$(cat openshift/master)
              export ROX_IMAGE_REGISTRY=docker.io
              export MAIN_IMAGE_TAG=$(make tag)
              export REGISTRY_PASSWORD=$DOCKER_IO_PASSWORD
              export REGISTRY_USERNAME=$DOCKER_IO_USERNAME
            EOF

            ./scripts/ci/openshift-gcr-secrets.sh

      - run:
          name: Deploy to remote cluster
          command: |
            ./deploy/openshift/deploy.sh
            oc -n stackrox get all

            source ./scripts/k8s/export-basic-auth-creds.sh ./deploy/openshift/
            cat >>"$BASH_ENV" <<EOF
              export ROX_USERNAME="$ROX_USERNAME"
              export ROX_PASSWORD="$ROX_PASSWORD"
            EOF

      - *setupCIMonitoring
      - *waitForAPI
      - *waitForSensorK8s

      - *restoreGradle
      - run:
          name: QA Automation Platform
          command: |
            if .circleci/pr_has_label.sh ci-no-qa-tests; then
              echo "Skipping QA tests because of the presence of the ci-no-qa-tests label..."
            else
              export CLUSTER=OPENSHIFT
              export HOSTNAME=localhost
              export PORT=${LOCAL_PORT}
              ./scripts/ci/create-webhookserver.sh oc
              if [ "${CIRCLE_BRANCH}" = "master" ]; then
                echo "On master, running all QA tests..."
                make -C qa-tests-backend test
              elif .circleci/pr_has_label.sh ci-all-qa-tests; then
                echo "ci-all-qa-tests label was specified, so running all QA tests..."
                make -C qa-tests-backend test
              else
                echo "On a PR branch, running BAT tests only..."
                make -C qa-tests-backend bat-test
              fi
            fi

      - *storeQATestResults
      - *storeQASpockReports

      - *restoreUI
      - *determineWhetherToRunUIDevServer
      - *runUIDevServer
      - *waitForUIDevServer
      - *runUIE2E
      - *collectImbuedUILogs
      - *storeImbuedUILogs

      - *collectK8sLogs
      - *storeK8sLogs

      - *storeCypressResults
      - *storeCypressScreenshots
      - *storeCypressVideos

      - run:
          name: Pack openshift volume
          command: |
            docker create -v /data --name openshift alpine:3.9 /bin/true
            docker cp openshift/id_rsa            openshift:/data
            docker cp openshift/id_rsa.pub        openshift:/data
            docker cp openshift/terraform.tfstate openshift:/data
          when: always

      - run:
          name: Destroy Openshift cluster
          command: |
            docker run --rm -t \
              --volumes-from openshift \
              -e GOOGLE_CREDENTIALS="$OPENSHIFT_TERRAFORM_CREDENTIALS" \
              stackrox/openshift-automation:terraform-$OPENSHIFT_AUTOMATION_VERSION destroy "${CIRCLE_SHA1:0:7}"
          when: always

  oss-audit:
    <<: *defaults
    steps:
      - checkout

      - run:
          name: Install ossls
          working_directory: /tmp
          command: |
            wget --quiet https://github.com/gruntwork-io/fetch/releases/download/v0.3.2/fetch_linux_amd64
            sudo install fetch_linux_amd64 /usr/bin/fetch
            export GITHUB_OAUTH_TOKEN="$GITHUB_TOKEN"
            fetch --repo="https://github.com/stackrox/ossls" --tag="0.3.0-rc1" --release-asset="ossls_linux_amd64" .
            sudo install ossls_linux_amd64 /usr/bin/ossls
            ossls -version

      - *restoreDep
      - *restoreUI

      - run:
          name: Install Go dependencies
          command: dep ensure

      - run:
          name: Install Javascript dependencies
          working_directory: ui
          command: yarn install --frozen-lockfile

      - run:
          name: Audit dependencies
          command: make ossls-audit

  mark-collector-release:
    <<: *defaults
    resource_class: small
    steps:
      - checkout
      - add_ssh_keys:
          fingerprints:
          - "7f:08:58:1e:80:80:6e:66:99:9a:37:cb:e9:96:0b:40"

      - run:
          name: Add SSH key of github.com
          command: |
            ssh-keyscan -H github.com >> ~/.ssh/known_hosts

      - run:
          name: Check out collector source code
          command: |
            mkdir -p /tmp/collector
            cd /tmp/collector
            git clone git@github.com:stackrox/collector.git .

      - run:
          name: Add current release version to RELEASED_VERSIONS file
          command: |
            collector_version="$(cat COLLECTOR_VERSION)"
            cd /tmp/collector
            git checkout master && git pull

            # We need to make sure the file ends with a newline so as not to corrupt it when appending.
            [[ ! -f RELEASED_VERSIONS ]] || sed -i'' -e '$a\' RELEASED_VERSIONS

            echo "${collector_version}  # Rox release ${CIRCLE_TAG} by ${CIRCLE_USERNAME} at $(date)" \
              >>RELEASED_VERSIONS
            git add RELEASED_VERSIONS
            git -c "user.name=roxbot" -c "user.email=roxbot@stackrox.com" commit \
                -m "Automatic update of RELEASED_VERSIONS file for Rox release ${CIRCLE_TAG}"
            git push

  push-release:
    <<: *defaults
    resource_class: small
    steps:
      - checkout
      - setup_remote_docker
      - attach_workspace:
          at: /go/src/github.com/stackrox/rox

      - run:
          name: Push image into stackrox.io
          command: |
            docker login -u "$DOCKER_IO_USERNAME" -p "$DOCKER_IO_PASSWORD" docker.io
            docker login -u "$STACKROX_IO_USERNAME" -p "$STACKROX_IO_PASSWORD" stackrox.io
            docker login -u "$STACKROX_IO_USERNAME" -p "$STACKROX_IO_PASSWORD" collector.stackrox.io

            MAIN_TAG=$(make tag)
            COLLECTOR_TAG=$(make collector-tag)

            docker pull docker.io/stackrox/main:$MAIN_TAG | cat
            docker tag  docker.io/stackrox/main:$MAIN_TAG stackrox.io/main:$MAIN_TAG
            docker push        stackrox.io/main:$MAIN_TAG | cat

            docker pull docker.io/stackrox/monitoring:$MAIN_TAG | cat
            docker tag  docker.io/stackrox/monitoring:$MAIN_TAG stackrox.io/monitoring:$MAIN_TAG
            docker push        stackrox.io/monitoring:$MAIN_TAG | cat

            docker pull    docker.io/stackrox/collector:$COLLECTOR_TAG | cat
            docker tag     docker.io/stackrox/collector:$COLLECTOR_TAG collector.stackrox.io/collector:$COLLECTOR_TAG
            docker push collector.stackrox.io/collector:$COLLECTOR_TAG | cat

      - run:
          name: Push roxctl to stackrox-hub
          command: |
            gcloud auth activate-service-account --key-file <(echo "$GOOGLE_CREDENTIALS_ROXCTL_UPLOAD")
            gcloud auth list
            MAIN_TAG=$(make tag)

            cd bazel-bin/roxctl
            for release in "${MAIN_TAG}" latest; do
              gsutil cp linux_amd64_pure_stripped/roxctl "gs://sr-roxc/${release}/bin/linux/roxctl"
              gsutil cp linux_amd64_pure_stripped/roxctl "gs://sr-roxc/${release}/bin/Linux/roxctl"

              gsutil cp darwin_amd64_pure_stripped/roxctl "gs://sr-roxc/${release}/bin/darwin/roxctl"
              gsutil cp darwin_amd64_pure_stripped/roxctl "gs://sr-roxc/${release}/bin/Darwin/roxctl"

              gsutil cp windows_amd64_pure_stripped/roxctl.exe "gs://sr-roxc/${release}/bin/windows/roxctl.exe"
              gsutil cp windows_amd64_pure_stripped/roxctl.exe "gs://sr-roxc/${release}/bin/Windows/roxctl.exe"
            done

workflows:
  version: 2
  build_all:
    jobs:
      - pre-build-ui:
          filters:
            tags:
              only: /.*/
      - pre-build-cli:
          filters:
            tags:
              only: /.*/
      - pre-build-go-binaries:
          filters:
            tags:
              only: /.*/
      - build:
          requires:
            - pre-build-ui
            - pre-build-cli
            - pre-build-go-binaries
          filters:
            tags:
              only: /.*/
      - build-rhel:
          requires:
            - pre-build-ui
            - pre-build-cli
            - pre-build-go-binaries
          filters:
            tags:
              only: /.*/
      - build-scale-monitoring-and-mock-server:
          filters:
            tags:
              only: /.*/
      - unit-tests:
          filters:
            tags:
              only: /.*/
      - style-checks:
          filters:
            tags:
              only: /.*/
      - integration-unit-tests:
          filters:
            tags:
              only: /.*/
      - k8s-tests:
          requires:
            - build
            - build-rhel
            - build-scale-monitoring-and-mock-server
          filters:
            tags:
              only: /.*/
      - qa-tests:
          requires:
            - build
            - build-rhel
            - build-scale-monitoring-and-mock-server
          filters:
            tags:
              only: /.*/
      - qa-tests-cos-ebpf:
          requires:
            - build
            - build-rhel
            - build-scale-monitoring-and-mock-server
          filters:
            tags:
              only: /.*/
      - upgrade-test:
          requires:
            - build
            - build-rhel
            - build-scale-monitoring-and-mock-server
          filters:
            tags:
              only: /.*/
      - scale:
          requires:
            - build
            - build-rhel
            - build-scale-monitoring-and-mock-server
          filters:
            tags:
              only: /.*/
      - provision-openshift:
          filters:
            tags:
              only:
              - /.*/
      - openshift-tests:
          requires:
            - build
            - provision-openshift
          filters:
            tags:
              only:
              - /.*/
      - oss-audit:
          filters:
            tags:
              only: /.*/
      # Push release only on tags.
      - mark-collector-release:
          requires:
            - build
          filters:
            branches:
              ignore: /.*/
            tags:
              only: /.*/
      - push-release:
          requires:
            - build
          filters:
            branches:
              ignore: /.*/
            tags:
              only: /.*/
