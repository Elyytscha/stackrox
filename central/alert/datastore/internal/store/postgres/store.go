// Code generated by pg-bindings generator. DO NOT EDIT.

package postgres

import (
	"context"
	"reflect"
	"time"

	"github.com/gogo/protobuf/proto"
	"github.com/jackc/pgx/v4"
	"github.com/jackc/pgx/v4/pgxpool"
	"github.com/stackrox/rox/central/globaldb"
	"github.com/stackrox/rox/central/metrics"
	"github.com/stackrox/rox/generated/storage"
	"github.com/stackrox/rox/pkg/logging"
	ops "github.com/stackrox/rox/pkg/metrics"
	"github.com/stackrox/rox/pkg/postgres/pgutils"
	"github.com/stackrox/rox/pkg/postgres/walker"
)

const (
	baseTable  = "alerts"
	countStmt  = "SELECT COUNT(*) FROM alerts"
	existsStmt = "SELECT EXISTS(SELECT 1 FROM alerts WHERE id = $1)"

	getStmt     = "SELECT serialized FROM alerts WHERE id = $1"
	deleteStmt  = "DELETE FROM alerts WHERE id = $1"
	walkStmt    = "SELECT serialized FROM alerts"
	getIDsStmt  = "SELECT id FROM alerts"
	getManyStmt = "SELECT serialized FROM alerts WHERE id = ANY($1::text[])"

	deleteManyStmt = "DELETE FROM alerts WHERE id = ANY($1::text[])"

	batchAfter = 100

	// using copyFrom, we may not even want to batch.  It would probably be simpler
	// to deal with failures if we just sent it all.  Something to think about as we
	// proceed and move into more e2e and larger performance testing
	batchSize = 10000
)

var (
	schema = walker.Walk(reflect.TypeOf((*storage.Alert)(nil)), baseTable)
	log    = logging.LoggerForModule()
)

func init() {
	globaldb.RegisterTable(schema)
}

type Store interface {
	Count(ctx context.Context) (int, error)
	Exists(ctx context.Context, id string) (bool, error)
	Get(ctx context.Context, id string) (*storage.Alert, bool, error)
	Upsert(ctx context.Context, obj *storage.Alert) error
	UpsertMany(ctx context.Context, objs []*storage.Alert) error
	Delete(ctx context.Context, id string) error
	GetIDs(ctx context.Context) ([]string, error)
	GetMany(ctx context.Context, ids []string) ([]*storage.Alert, []int, error)
	DeleteMany(ctx context.Context, ids []string) error

	Walk(ctx context.Context, fn func(obj *storage.Alert) error) error

	AckKeysIndexed(ctx context.Context, keys ...string) error
	GetKeysToIndex(ctx context.Context) ([]string, error)
}

type storeImpl struct {
	db *pgxpool.Pool
}

func createTableAlerts(ctx context.Context, db *pgxpool.Pool) {
	table := `
create table if not exists alerts (
    id varchar,
    policy_id varchar,
    policy_name varchar,
    policy_description varchar,
    policy_rationale varchar,
    policy_remediation varchar,
    policy_disabled bool,
    policy_categories text[],
    policy_lifecyclestages int[],
    policy_eventsource integer,
    policy_severity integer,
    policy_enforcementactions int[],
    policy_notifiers text[],
    policy_lastupdated timestamp,
    policy_sortname varchar,
    policy_sortlifecyclestage varchar,
    policy_sortenforcement bool,
    policy_policyversion varchar,
    policy_criterialocked bool,
    policy_mitrevectorslocked bool,
    policy_isdefault bool,
    lifecyclestage integer,
    deployment_id varchar,
    deployment_name varchar,
    deployment_type varchar,
    deployment_namespace varchar,
    deployment_namespaceid varchar,
    deployment_labels jsonb,
    deployment_clusterid varchar,
    deployment_clustername varchar,
    deployment_annotations jsonb,
    deployment_inactive bool,
    image_id varchar,
    image_name_registry varchar,
    image_name_remote varchar,
    image_name_tag varchar,
    image_name_fullname varchar,
    image_notpullable bool,
    image_isclusterlocal bool,
    resource_resourcetype integer,
    resource_name varchar,
    resource_clusterid varchar,
    resource_clustername varchar,
    resource_namespace varchar,
    resource_namespaceid varchar,
    processviolation_message varchar,
    enforcement_action integer,
    enforcement_message varchar,
    time timestamp,
    firstoccurred timestamp,
    resolvedat timestamp,
    state integer,
    snoozetill timestamp,
    tags text[],
    serialized bytea,
    PRIMARY KEY(id)
)
`

	_, err := db.Exec(ctx, table)
	if err != nil {
		log.Panicf("Error creating table %s: %v", table, err)
	}

	indexes := []string{}
	for _, index := range indexes {
		if _, err := db.Exec(ctx, index); err != nil {
			log.Panicf("Error creating index %s: %v", index, err)
		}
	}

	createTableAlertsWhitelists(ctx, db)
	createTableAlertsExclusions(ctx, db)
	createTableAlertsScope(ctx, db)
	createTableAlertsPolicySections(ctx, db)
	createTableAlertsMitreAttackVectors(ctx, db)
	createTableAlertsContainers(ctx, db)
	createTableAlertsViolations(ctx, db)
	createTableAlertsProcesses(ctx, db)
}

func createTableAlertsWhitelists(ctx context.Context, db *pgxpool.Pool) {
	table := `
create table if not exists alerts_Whitelists (
    alertid varchar,
    idx integer,
    name varchar,
    deployment_name varchar,
    deployment_scope_cluster varchar,
    deployment_scope_namespace varchar,
    deployment_scope_label_key varchar,
    deployment_scope_label_value varchar,
    image_name varchar,
    expiration timestamp,
    PRIMARY KEY(alertid, idx),
    CONSTRAINT fk_parent_table_0 FOREIGN KEY (alertid) REFERENCES alerts(id) ON DELETE CASCADE
)
`

	_, err := db.Exec(ctx, table)
	if err != nil {
		log.Panicf("Error creating table %s: %v", table, err)
	}

	indexes := []string{

		"create index if not exists alertsWhitelists_idx on alerts_Whitelists using btree(idx)",
	}
	for _, index := range indexes {
		if _, err := db.Exec(ctx, index); err != nil {
			log.Panicf("Error creating index %s: %v", index, err)
		}
	}

}

func createTableAlertsExclusions(ctx context.Context, db *pgxpool.Pool) {
	table := `
create table if not exists alerts_Exclusions (
    alertid varchar,
    idx integer,
    name varchar,
    deployment_name varchar,
    deployment_scope_cluster varchar,
    deployment_scope_namespace varchar,
    deployment_scope_label_key varchar,
    deployment_scope_label_value varchar,
    image_name varchar,
    expiration timestamp,
    PRIMARY KEY(alertid, idx),
    CONSTRAINT fk_parent_table_0 FOREIGN KEY (alertid) REFERENCES alerts(id) ON DELETE CASCADE
)
`

	_, err := db.Exec(ctx, table)
	if err != nil {
		log.Panicf("Error creating table %s: %v", table, err)
	}

	indexes := []string{

		"create index if not exists alertsExclusions_idx on alerts_Exclusions using btree(idx)",
	}
	for _, index := range indexes {
		if _, err := db.Exec(ctx, index); err != nil {
			log.Panicf("Error creating index %s: %v", index, err)
		}
	}

}

func createTableAlertsScope(ctx context.Context, db *pgxpool.Pool) {
	table := `
create table if not exists alerts_Scope (
    alertid varchar,
    idx integer,
    cluster varchar,
    namespace varchar,
    label_key varchar,
    label_value varchar,
    PRIMARY KEY(alertid, idx),
    CONSTRAINT fk_parent_table_0 FOREIGN KEY (alertid) REFERENCES alerts(id) ON DELETE CASCADE
)
`

	_, err := db.Exec(ctx, table)
	if err != nil {
		log.Panicf("Error creating table %s: %v", table, err)
	}

	indexes := []string{

		"create index if not exists alertsScope_idx on alerts_Scope using btree(idx)",
	}
	for _, index := range indexes {
		if _, err := db.Exec(ctx, index); err != nil {
			log.Panicf("Error creating index %s: %v", index, err)
		}
	}

}

func createTableAlertsPolicySections(ctx context.Context, db *pgxpool.Pool) {
	table := `
create table if not exists alerts_PolicySections (
    alertid varchar,
    idx integer,
    sectionname varchar,
    PRIMARY KEY(alertid, idx),
    CONSTRAINT fk_parent_table_0 FOREIGN KEY (alertid) REFERENCES alerts(id) ON DELETE CASCADE
)
`

	_, err := db.Exec(ctx, table)
	if err != nil {
		log.Panicf("Error creating table %s: %v", table, err)
	}

	indexes := []string{

		"create index if not exists alertsPolicySections_idx on alerts_PolicySections using btree(idx)",
	}
	for _, index := range indexes {
		if _, err := db.Exec(ctx, index); err != nil {
			log.Panicf("Error creating index %s: %v", index, err)
		}
	}

	createTableAlertsPolicySectionsPolicyGroups(ctx, db)
}

func createTableAlertsPolicySectionsPolicyGroups(ctx context.Context, db *pgxpool.Pool) {
	table := `
create table if not exists alerts_PolicySections_PolicyGroups (
    alertid varchar,
    policysectionidx integer,
    idx integer,
    fieldname varchar,
    booleanoperator integer,
    negate bool,
    PRIMARY KEY(alertid, policysectionidx, idx),
    CONSTRAINT fk_parent_table_0 FOREIGN KEY (alertid, policysectionidx) REFERENCES alerts_PolicySections(alertid, idx) ON DELETE CASCADE
)
`

	_, err := db.Exec(ctx, table)
	if err != nil {
		log.Panicf("Error creating table %s: %v", table, err)
	}

	indexes := []string{

		"create index if not exists alertsPolicySectionsPolicyGroups_idx on alerts_PolicySections_PolicyGroups using btree(idx)",
	}
	for _, index := range indexes {
		if _, err := db.Exec(ctx, index); err != nil {
			log.Panicf("Error creating index %s: %v", index, err)
		}
	}

	createTableAlertsPolicySectionsPolicyGroupsValues(ctx, db)
}

func createTableAlertsPolicySectionsPolicyGroupsValues(ctx context.Context, db *pgxpool.Pool) {
	table := `
create table if not exists alerts_PolicySections_PolicyGroups_Values (
    alertid varchar,
    policysectionidx integer,
    policygroupidx integer,
    idx integer,
    value varchar,
    PRIMARY KEY(alertid, policysectionidx, policygroupidx, idx),
    CONSTRAINT fk_parent_table_0 FOREIGN KEY (alertid, policysectionidx, policygroupidx) REFERENCES alerts_PolicySections_PolicyGroups(alertid, policysectionidx, idx) ON DELETE CASCADE
)
`

	_, err := db.Exec(ctx, table)
	if err != nil {
		log.Panicf("Error creating table %s: %v", table, err)
	}

	indexes := []string{

		"create index if not exists alertsPolicySectionsPolicyGroupsValues_idx on alerts_PolicySections_PolicyGroups_Values using btree(idx)",
	}
	for _, index := range indexes {
		if _, err := db.Exec(ctx, index); err != nil {
			log.Panicf("Error creating index %s: %v", index, err)
		}
	}

}

func createTableAlertsMitreAttackVectors(ctx context.Context, db *pgxpool.Pool) {
	table := `
create table if not exists alerts_MitreAttackVectors (
    alertid varchar,
    idx integer,
    tactic varchar,
    techniques text[],
    PRIMARY KEY(alertid, idx),
    CONSTRAINT fk_parent_table_0 FOREIGN KEY (alertid) REFERENCES alerts(id) ON DELETE CASCADE
)
`

	_, err := db.Exec(ctx, table)
	if err != nil {
		log.Panicf("Error creating table %s: %v", table, err)
	}

	indexes := []string{

		"create index if not exists alertsMitreAttackVectors_idx on alerts_MitreAttackVectors using btree(idx)",
	}
	for _, index := range indexes {
		if _, err := db.Exec(ctx, index); err != nil {
			log.Panicf("Error creating index %s: %v", index, err)
		}
	}

}

func createTableAlertsContainers(ctx context.Context, db *pgxpool.Pool) {
	table := `
create table if not exists alerts_Containers (
    alertid varchar,
    idx integer,
    image_id varchar,
    image_name_registry varchar,
    image_name_remote varchar,
    image_name_tag varchar,
    image_name_fullname varchar,
    image_notpullable bool,
    image_isclusterlocal bool,
    name varchar,
    PRIMARY KEY(alertid, idx),
    CONSTRAINT fk_parent_table_0 FOREIGN KEY (alertid) REFERENCES alerts(id) ON DELETE CASCADE
)
`

	_, err := db.Exec(ctx, table)
	if err != nil {
		log.Panicf("Error creating table %s: %v", table, err)
	}

	indexes := []string{

		"create index if not exists alertsContainers_idx on alerts_Containers using btree(idx)",
	}
	for _, index := range indexes {
		if _, err := db.Exec(ctx, index); err != nil {
			log.Panicf("Error creating index %s: %v", index, err)
		}
	}

}

func createTableAlertsViolations(ctx context.Context, db *pgxpool.Pool) {
	table := `
create table if not exists alerts_Violations (
    alertid varchar,
    idx integer,
    message varchar,
    networkflowinfo_protocol integer,
    networkflowinfo_source_name varchar,
    networkflowinfo_source_entitytype integer,
    networkflowinfo_source_deploymentnamespace varchar,
    networkflowinfo_source_deploymenttype varchar,
    networkflowinfo_source_port integer,
    networkflowinfo_destination_name varchar,
    networkflowinfo_destination_entitytype integer,
    networkflowinfo_destination_deploymentnamespace varchar,
    networkflowinfo_destination_deploymenttype varchar,
    networkflowinfo_destination_port integer,
    type integer,
    time timestamp,
    PRIMARY KEY(alertid, idx),
    CONSTRAINT fk_parent_table_0 FOREIGN KEY (alertid) REFERENCES alerts(id) ON DELETE CASCADE
)
`

	_, err := db.Exec(ctx, table)
	if err != nil {
		log.Panicf("Error creating table %s: %v", table, err)
	}

	indexes := []string{

		"create index if not exists alertsViolations_idx on alerts_Violations using btree(idx)",
	}
	for _, index := range indexes {
		if _, err := db.Exec(ctx, index); err != nil {
			log.Panicf("Error creating index %s: %v", index, err)
		}
	}

	createTableAlertsViolationsAttrs(ctx, db)
}

func createTableAlertsViolationsAttrs(ctx context.Context, db *pgxpool.Pool) {
	table := `
create table if not exists alerts_Violations_Attrs (
    alertid varchar,
    alert_violationidx integer,
    idx integer,
    key varchar,
    value varchar,
    PRIMARY KEY(alertid, alert_violationidx, idx),
    CONSTRAINT fk_parent_table_0 FOREIGN KEY (alertid, alert_violationidx) REFERENCES alerts_Violations(alertid, idx) ON DELETE CASCADE
)
`

	_, err := db.Exec(ctx, table)
	if err != nil {
		log.Panicf("Error creating table %s: %v", table, err)
	}

	indexes := []string{

		"create index if not exists alertsViolationsAttrs_idx on alerts_Violations_Attrs using btree(idx)",
	}
	for _, index := range indexes {
		if _, err := db.Exec(ctx, index); err != nil {
			log.Panicf("Error creating index %s: %v", index, err)
		}
	}

}

func createTableAlertsProcesses(ctx context.Context, db *pgxpool.Pool) {
	table := `
create table if not exists alerts_Processes (
    alertid varchar,
    idx integer,
    id varchar,
    deploymentid varchar,
    containername varchar,
    podid varchar,
    poduid varchar,
    signal_id varchar,
    signal_containerid varchar,
    signal_time timestamp,
    signal_name varchar,
    signal_args varchar,
    signal_execfilepath varchar,
    signal_pid integer,
    signal_uid integer,
    signal_gid integer,
    signal_lineage text[],
    signal_scraped bool,
    clusterid varchar,
    namespace varchar,
    containerstarttime timestamp,
    imageid varchar,
    PRIMARY KEY(alertid, idx),
    CONSTRAINT fk_parent_table_0 FOREIGN KEY (alertid) REFERENCES alerts(id) ON DELETE CASCADE
)
`

	_, err := db.Exec(ctx, table)
	if err != nil {
		log.Panicf("Error creating table %s: %v", table, err)
	}

	indexes := []string{

		"create index if not exists alertsProcesses_idx on alerts_Processes using btree(idx)",
	}
	for _, index := range indexes {
		if _, err := db.Exec(ctx, index); err != nil {
			log.Panicf("Error creating index %s: %v", index, err)
		}
	}

	createTableAlertsProcessesLineageInfo(ctx, db)
}

func createTableAlertsProcessesLineageInfo(ctx context.Context, db *pgxpool.Pool) {
	table := `
create table if not exists alerts_Processes_LineageInfo (
    alertid varchar,
    processindicatoridx integer,
    idx integer,
    parentuid integer,
    parentexecfilepath varchar,
    PRIMARY KEY(alertid, processindicatoridx, idx),
    CONSTRAINT fk_parent_table_0 FOREIGN KEY (alertid, processindicatoridx) REFERENCES alerts_Processes(alertid, idx) ON DELETE CASCADE
)
`

	_, err := db.Exec(ctx, table)
	if err != nil {
		log.Panicf("Error creating table %s: %v", table, err)
	}

	indexes := []string{

		"create index if not exists alertsProcessesLineageInfo_idx on alerts_Processes_LineageInfo using btree(idx)",
	}
	for _, index := range indexes {
		if _, err := db.Exec(ctx, index); err != nil {
			log.Panicf("Error creating index %s: %v", index, err)
		}
	}

}

func insertIntoAlerts(ctx context.Context, tx pgx.Tx, obj *storage.Alert) error {

	serialized, marshalErr := obj.Marshal()
	if marshalErr != nil {
		return marshalErr
	}

	values := []interface{}{
		// parent primary keys start
		obj.GetId(),
		obj.GetPolicy().GetId(),
		obj.GetPolicy().GetName(),
		obj.GetPolicy().GetDescription(),
		obj.GetPolicy().GetRationale(),
		obj.GetPolicy().GetRemediation(),
		obj.GetPolicy().GetDisabled(),
		obj.GetPolicy().GetCategories(),
		obj.GetPolicy().GetLifecycleStages(),
		obj.GetPolicy().GetEventSource(),
		obj.GetPolicy().GetSeverity(),
		obj.GetPolicy().GetEnforcementActions(),
		obj.GetPolicy().GetNotifiers(),
		pgutils.NilOrTime(obj.GetPolicy().GetLastUpdated()),
		obj.GetPolicy().GetSORTName(),
		obj.GetPolicy().GetSORTLifecycleStage(),
		obj.GetPolicy().GetSORTEnforcement(),
		obj.GetPolicy().GetPolicyVersion(),
		obj.GetPolicy().GetCriteriaLocked(),
		obj.GetPolicy().GetMitreVectorsLocked(),
		obj.GetPolicy().GetIsDefault(),
		obj.GetLifecycleStage(),
		obj.GetDeployment().GetId(),
		obj.GetDeployment().GetName(),
		obj.GetDeployment().GetType(),
		obj.GetDeployment().GetNamespace(),
		obj.GetDeployment().GetNamespaceId(),
		obj.GetDeployment().GetLabels(),
		obj.GetDeployment().GetClusterId(),
		obj.GetDeployment().GetClusterName(),
		obj.GetDeployment().GetAnnotations(),
		obj.GetDeployment().GetInactive(),
		obj.GetImage().GetId(),
		obj.GetImage().GetName().GetRegistry(),
		obj.GetImage().GetName().GetRemote(),
		obj.GetImage().GetName().GetTag(),
		obj.GetImage().GetName().GetFullName(),
		obj.GetImage().GetNotPullable(),
		obj.GetImage().GetIsClusterLocal(),
		obj.GetResource().GetResourceType(),
		obj.GetResource().GetName(),
		obj.GetResource().GetClusterId(),
		obj.GetResource().GetClusterName(),
		obj.GetResource().GetNamespace(),
		obj.GetResource().GetNamespaceId(),
		obj.GetProcessViolation().GetMessage(),
		obj.GetEnforcement().GetAction(),
		obj.GetEnforcement().GetMessage(),
		pgutils.NilOrTime(obj.GetTime()),
		pgutils.NilOrTime(obj.GetFirstOccurred()),
		pgutils.NilOrTime(obj.GetResolvedAt()),
		obj.GetState(),
		pgutils.NilOrTime(obj.GetSnoozeTill()),
		obj.GetTags(),
		serialized,
	}

	finalStr := "INSERT INTO alerts (id, policy_id, policy_name, policy_description, policy_rationale, policy_remediation, policy_disabled, policy_categories, policy_lifecyclestages, policy_eventsource, policy_severity, policy_enforcementactions, policy_notifiers, policy_lastupdated, policy_sortname, policy_sortlifecyclestage, policy_sortenforcement, policy_policyversion, policy_criterialocked, policy_mitrevectorslocked, policy_isdefault, lifecyclestage, deployment_id, deployment_name, deployment_type, deployment_namespace, deployment_namespaceid, deployment_labels, deployment_clusterid, deployment_clustername, deployment_annotations, deployment_inactive, image_id, image_name_registry, image_name_remote, image_name_tag, image_name_fullname, image_notpullable, image_isclusterlocal, resource_resourcetype, resource_name, resource_clusterid, resource_clustername, resource_namespace, resource_namespaceid, processviolation_message, enforcement_action, enforcement_message, time, firstoccurred, resolvedat, state, snoozetill, tags, serialized) VALUES($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16, $17, $18, $19, $20, $21, $22, $23, $24, $25, $26, $27, $28, $29, $30, $31, $32, $33, $34, $35, $36, $37, $38, $39, $40, $41, $42, $43, $44, $45, $46, $47, $48, $49, $50, $51, $52, $53, $54, $55) ON CONFLICT(id) DO UPDATE SET id = EXCLUDED.id, policy_id = EXCLUDED.policy_id, policy_name = EXCLUDED.policy_name, policy_description = EXCLUDED.policy_description, policy_rationale = EXCLUDED.policy_rationale, policy_remediation = EXCLUDED.policy_remediation, policy_disabled = EXCLUDED.policy_disabled, policy_categories = EXCLUDED.policy_categories, policy_lifecyclestages = EXCLUDED.policy_lifecyclestages, policy_eventsource = EXCLUDED.policy_eventsource, policy_severity = EXCLUDED.policy_severity, policy_enforcementactions = EXCLUDED.policy_enforcementactions, policy_notifiers = EXCLUDED.policy_notifiers, policy_lastupdated = EXCLUDED.policy_lastupdated, policy_sortname = EXCLUDED.policy_sortname, policy_sortlifecyclestage = EXCLUDED.policy_sortlifecyclestage, policy_sortenforcement = EXCLUDED.policy_sortenforcement, policy_policyversion = EXCLUDED.policy_policyversion, policy_criterialocked = EXCLUDED.policy_criterialocked, policy_mitrevectorslocked = EXCLUDED.policy_mitrevectorslocked, policy_isdefault = EXCLUDED.policy_isdefault, lifecyclestage = EXCLUDED.lifecyclestage, deployment_id = EXCLUDED.deployment_id, deployment_name = EXCLUDED.deployment_name, deployment_type = EXCLUDED.deployment_type, deployment_namespace = EXCLUDED.deployment_namespace, deployment_namespaceid = EXCLUDED.deployment_namespaceid, deployment_labels = EXCLUDED.deployment_labels, deployment_clusterid = EXCLUDED.deployment_clusterid, deployment_clustername = EXCLUDED.deployment_clustername, deployment_annotations = EXCLUDED.deployment_annotations, deployment_inactive = EXCLUDED.deployment_inactive, image_id = EXCLUDED.image_id, image_name_registry = EXCLUDED.image_name_registry, image_name_remote = EXCLUDED.image_name_remote, image_name_tag = EXCLUDED.image_name_tag, image_name_fullname = EXCLUDED.image_name_fullname, image_notpullable = EXCLUDED.image_notpullable, image_isclusterlocal = EXCLUDED.image_isclusterlocal, resource_resourcetype = EXCLUDED.resource_resourcetype, resource_name = EXCLUDED.resource_name, resource_clusterid = EXCLUDED.resource_clusterid, resource_clustername = EXCLUDED.resource_clustername, resource_namespace = EXCLUDED.resource_namespace, resource_namespaceid = EXCLUDED.resource_namespaceid, processviolation_message = EXCLUDED.processviolation_message, enforcement_action = EXCLUDED.enforcement_action, enforcement_message = EXCLUDED.enforcement_message, time = EXCLUDED.time, firstoccurred = EXCLUDED.firstoccurred, resolvedat = EXCLUDED.resolvedat, state = EXCLUDED.state, snoozetill = EXCLUDED.snoozetill, tags = EXCLUDED.tags, serialized = EXCLUDED.serialized"
	_, err := tx.Exec(ctx, finalStr, values...)
	if err != nil {
		return err
	}

	var query string

	for childIdx, child := range obj.GetPolicy().GetWhitelists() {
		if err := insertIntoAlertsWhitelists(ctx, tx, child, obj.GetId(), childIdx); err != nil {
			return err
		}
	}

	query = "delete from alerts_Whitelists where alertid = $1 AND idx >= $2"
	_, err = tx.Exec(ctx, query, obj.GetId(), len(obj.GetPolicy().GetWhitelists()))
	if err != nil {
		return err
	}
	for childIdx, child := range obj.GetPolicy().GetExclusions() {
		if err := insertIntoAlertsExclusions(ctx, tx, child, obj.GetId(), childIdx); err != nil {
			return err
		}
	}

	query = "delete from alerts_Exclusions where alertid = $1 AND idx >= $2"
	_, err = tx.Exec(ctx, query, obj.GetId(), len(obj.GetPolicy().GetExclusions()))
	if err != nil {
		return err
	}
	for childIdx, child := range obj.GetPolicy().GetScope() {
		if err := insertIntoAlertsScope(ctx, tx, child, obj.GetId(), childIdx); err != nil {
			return err
		}
	}

	query = "delete from alerts_Scope where alertid = $1 AND idx >= $2"
	_, err = tx.Exec(ctx, query, obj.GetId(), len(obj.GetPolicy().GetScope()))
	if err != nil {
		return err
	}
	for childIdx, child := range obj.GetPolicy().GetPolicySections() {
		if err := insertIntoAlertsPolicySections(ctx, tx, child, obj.GetId(), childIdx); err != nil {
			return err
		}
	}

	query = "delete from alerts_PolicySections where alertid = $1 AND idx >= $2"
	_, err = tx.Exec(ctx, query, obj.GetId(), len(obj.GetPolicy().GetPolicySections()))
	if err != nil {
		return err
	}
	for childIdx, child := range obj.GetPolicy().GetMitreAttackVectors() {
		if err := insertIntoAlertsMitreAttackVectors(ctx, tx, child, obj.GetId(), childIdx); err != nil {
			return err
		}
	}

	query = "delete from alerts_MitreAttackVectors where alertid = $1 AND idx >= $2"
	_, err = tx.Exec(ctx, query, obj.GetId(), len(obj.GetPolicy().GetMitreAttackVectors()))
	if err != nil {
		return err
	}
	for childIdx, child := range obj.GetDeployment().GetContainers() {
		if err := insertIntoAlertsContainers(ctx, tx, child, obj.GetId(), childIdx); err != nil {
			return err
		}
	}

	query = "delete from alerts_Containers where alertid = $1 AND idx >= $2"
	_, err = tx.Exec(ctx, query, obj.GetId(), len(obj.GetDeployment().GetContainers()))
	if err != nil {
		return err
	}
	for childIdx, child := range obj.GetViolations() {
		if err := insertIntoAlertsViolations(ctx, tx, child, obj.GetId(), childIdx); err != nil {
			return err
		}
	}

	query = "delete from alerts_Violations where alertid = $1 AND idx >= $2"
	_, err = tx.Exec(ctx, query, obj.GetId(), len(obj.GetViolations()))
	if err != nil {
		return err
	}
	for childIdx, child := range obj.GetProcessViolation().GetProcesses() {
		if err := insertIntoAlertsProcesses(ctx, tx, child, obj.GetId(), childIdx); err != nil {
			return err
		}
	}

	query = "delete from alerts_Processes where alertid = $1 AND idx >= $2"
	_, err = tx.Exec(ctx, query, obj.GetId(), len(obj.GetProcessViolation().GetProcesses()))
	if err != nil {
		return err
	}
	return nil
}

func insertIntoAlertsWhitelists(ctx context.Context, tx pgx.Tx, obj *storage.Exclusion, alertid string, idx int) error {

	values := []interface{}{
		// parent primary keys start
		alertid,
		idx,
		obj.GetName(),
		obj.GetDeployment().GetName(),
		obj.GetDeployment().GetScope().GetCluster(),
		obj.GetDeployment().GetScope().GetNamespace(),
		obj.GetDeployment().GetScope().GetLabel().GetKey(),
		obj.GetDeployment().GetScope().GetLabel().GetValue(),
		obj.GetImage().GetName(),
		pgutils.NilOrTime(obj.GetExpiration()),
	}

	finalStr := "INSERT INTO alerts_Whitelists (alertid, idx, name, deployment_name, deployment_scope_cluster, deployment_scope_namespace, deployment_scope_label_key, deployment_scope_label_value, image_name, expiration) VALUES($1, $2, $3, $4, $5, $6, $7, $8, $9, $10) ON CONFLICT(alertid, idx) DO UPDATE SET alertid = EXCLUDED.alertid, idx = EXCLUDED.idx, name = EXCLUDED.name, deployment_name = EXCLUDED.deployment_name, deployment_scope_cluster = EXCLUDED.deployment_scope_cluster, deployment_scope_namespace = EXCLUDED.deployment_scope_namespace, deployment_scope_label_key = EXCLUDED.deployment_scope_label_key, deployment_scope_label_value = EXCLUDED.deployment_scope_label_value, image_name = EXCLUDED.image_name, expiration = EXCLUDED.expiration"
	_, err := tx.Exec(ctx, finalStr, values...)
	if err != nil {
		return err
	}

	return nil
}

func insertIntoAlertsExclusions(ctx context.Context, tx pgx.Tx, obj *storage.Exclusion, alertid string, idx int) error {

	values := []interface{}{
		// parent primary keys start
		alertid,
		idx,
		obj.GetName(),
		obj.GetDeployment().GetName(),
		obj.GetDeployment().GetScope().GetCluster(),
		obj.GetDeployment().GetScope().GetNamespace(),
		obj.GetDeployment().GetScope().GetLabel().GetKey(),
		obj.GetDeployment().GetScope().GetLabel().GetValue(),
		obj.GetImage().GetName(),
		pgutils.NilOrTime(obj.GetExpiration()),
	}

	finalStr := "INSERT INTO alerts_Exclusions (alertid, idx, name, deployment_name, deployment_scope_cluster, deployment_scope_namespace, deployment_scope_label_key, deployment_scope_label_value, image_name, expiration) VALUES($1, $2, $3, $4, $5, $6, $7, $8, $9, $10) ON CONFLICT(alertid, idx) DO UPDATE SET alertid = EXCLUDED.alertid, idx = EXCLUDED.idx, name = EXCLUDED.name, deployment_name = EXCLUDED.deployment_name, deployment_scope_cluster = EXCLUDED.deployment_scope_cluster, deployment_scope_namespace = EXCLUDED.deployment_scope_namespace, deployment_scope_label_key = EXCLUDED.deployment_scope_label_key, deployment_scope_label_value = EXCLUDED.deployment_scope_label_value, image_name = EXCLUDED.image_name, expiration = EXCLUDED.expiration"
	_, err := tx.Exec(ctx, finalStr, values...)
	if err != nil {
		return err
	}

	return nil
}

func insertIntoAlertsScope(ctx context.Context, tx pgx.Tx, obj *storage.Scope, alertid string, idx int) error {

	values := []interface{}{
		// parent primary keys start
		alertid,
		idx,
		obj.GetCluster(),
		obj.GetNamespace(),
		obj.GetLabel().GetKey(),
		obj.GetLabel().GetValue(),
	}

	finalStr := "INSERT INTO alerts_Scope (alertid, idx, cluster, namespace, label_key, label_value) VALUES($1, $2, $3, $4, $5, $6) ON CONFLICT(alertid, idx) DO UPDATE SET alertid = EXCLUDED.alertid, idx = EXCLUDED.idx, cluster = EXCLUDED.cluster, namespace = EXCLUDED.namespace, label_key = EXCLUDED.label_key, label_value = EXCLUDED.label_value"
	_, err := tx.Exec(ctx, finalStr, values...)
	if err != nil {
		return err
	}

	return nil
}

func insertIntoAlertsPolicySections(ctx context.Context, tx pgx.Tx, obj *storage.PolicySection, alertid string, idx int) error {

	values := []interface{}{
		// parent primary keys start
		alertid,
		idx,
		obj.GetSectionName(),
	}

	finalStr := "INSERT INTO alerts_PolicySections (alertid, idx, sectionname) VALUES($1, $2, $3) ON CONFLICT(alertid, idx) DO UPDATE SET alertid = EXCLUDED.alertid, idx = EXCLUDED.idx, sectionname = EXCLUDED.sectionname"
	_, err := tx.Exec(ctx, finalStr, values...)
	if err != nil {
		return err
	}

	var query string

	for childIdx, child := range obj.GetPolicyGroups() {
		if err := insertIntoAlertsPolicySectionsPolicyGroups(ctx, tx, child, alertid, idx, childIdx); err != nil {
			return err
		}
	}

	query = "delete from alerts_PolicySections_PolicyGroups where alertid = $1 AND policysectionidx = $2 AND idx >= $3"
	_, err = tx.Exec(ctx, query, alertid, idx, len(obj.GetPolicyGroups()))
	if err != nil {
		return err
	}
	return nil
}

func insertIntoAlertsPolicySectionsPolicyGroups(ctx context.Context, tx pgx.Tx, obj *storage.PolicyGroup, alertid string, policysectionidx int, idx int) error {

	values := []interface{}{
		// parent primary keys start
		alertid,
		policysectionidx,
		idx,
		obj.GetFieldName(),
		obj.GetBooleanOperator(),
		obj.GetNegate(),
	}

	finalStr := "INSERT INTO alerts_PolicySections_PolicyGroups (alertid, policysectionidx, idx, fieldname, booleanoperator, negate) VALUES($1, $2, $3, $4, $5, $6) ON CONFLICT(alertid, policysectionidx, idx) DO UPDATE SET alertid = EXCLUDED.alertid, policysectionidx = EXCLUDED.policysectionidx, idx = EXCLUDED.idx, fieldname = EXCLUDED.fieldname, booleanoperator = EXCLUDED.booleanoperator, negate = EXCLUDED.negate"
	_, err := tx.Exec(ctx, finalStr, values...)
	if err != nil {
		return err
	}

	var query string

	for childIdx, child := range obj.GetValues() {
		if err := insertIntoAlertsPolicySectionsPolicyGroupsValues(ctx, tx, child, alertid, policysectionidx, idx, childIdx); err != nil {
			return err
		}
	}

	query = "delete from alerts_PolicySections_PolicyGroups_Values where alertid = $1 AND policysectionidx = $2 AND policygroupidx = $3 AND idx >= $4"
	_, err = tx.Exec(ctx, query, alertid, policysectionidx, idx, len(obj.GetValues()))
	if err != nil {
		return err
	}
	return nil
}

func insertIntoAlertsPolicySectionsPolicyGroupsValues(ctx context.Context, tx pgx.Tx, obj *storage.PolicyValue, alertid string, policysectionidx int, policygroupidx int, idx int) error {

	values := []interface{}{
		// parent primary keys start
		alertid,
		policysectionidx,
		policygroupidx,
		idx,
		obj.GetValue(),
	}

	finalStr := "INSERT INTO alerts_PolicySections_PolicyGroups_Values (alertid, policysectionidx, policygroupidx, idx, value) VALUES($1, $2, $3, $4, $5) ON CONFLICT(alertid, policysectionidx, policygroupidx, idx) DO UPDATE SET alertid = EXCLUDED.alertid, policysectionidx = EXCLUDED.policysectionidx, policygroupidx = EXCLUDED.policygroupidx, idx = EXCLUDED.idx, value = EXCLUDED.value"
	_, err := tx.Exec(ctx, finalStr, values...)
	if err != nil {
		return err
	}

	return nil
}

func insertIntoAlertsMitreAttackVectors(ctx context.Context, tx pgx.Tx, obj *storage.Policy_MitreAttackVectors, alertid string, idx int) error {

	values := []interface{}{
		// parent primary keys start
		alertid,
		idx,
		obj.GetTactic(),
		obj.GetTechniques(),
	}

	finalStr := "INSERT INTO alerts_MitreAttackVectors (alertid, idx, tactic, techniques) VALUES($1, $2, $3, $4) ON CONFLICT(alertid, idx) DO UPDATE SET alertid = EXCLUDED.alertid, idx = EXCLUDED.idx, tactic = EXCLUDED.tactic, techniques = EXCLUDED.techniques"
	_, err := tx.Exec(ctx, finalStr, values...)
	if err != nil {
		return err
	}

	return nil
}

func insertIntoAlertsContainers(ctx context.Context, tx pgx.Tx, obj *storage.Alert_Deployment_Container, alertid string, idx int) error {

	values := []interface{}{
		// parent primary keys start
		alertid,
		idx,
		obj.GetImage().GetId(),
		obj.GetImage().GetName().GetRegistry(),
		obj.GetImage().GetName().GetRemote(),
		obj.GetImage().GetName().GetTag(),
		obj.GetImage().GetName().GetFullName(),
		obj.GetImage().GetNotPullable(),
		obj.GetImage().GetIsClusterLocal(),
		obj.GetName(),
	}

	finalStr := "INSERT INTO alerts_Containers (alertid, idx, image_id, image_name_registry, image_name_remote, image_name_tag, image_name_fullname, image_notpullable, image_isclusterlocal, name) VALUES($1, $2, $3, $4, $5, $6, $7, $8, $9, $10) ON CONFLICT(alertid, idx) DO UPDATE SET alertid = EXCLUDED.alertid, idx = EXCLUDED.idx, image_id = EXCLUDED.image_id, image_name_registry = EXCLUDED.image_name_registry, image_name_remote = EXCLUDED.image_name_remote, image_name_tag = EXCLUDED.image_name_tag, image_name_fullname = EXCLUDED.image_name_fullname, image_notpullable = EXCLUDED.image_notpullable, image_isclusterlocal = EXCLUDED.image_isclusterlocal, name = EXCLUDED.name"
	_, err := tx.Exec(ctx, finalStr, values...)
	if err != nil {
		return err
	}

	return nil
}

func insertIntoAlertsViolations(ctx context.Context, tx pgx.Tx, obj *storage.Alert_Violation, alertid string, idx int) error {

	values := []interface{}{
		// parent primary keys start
		alertid,
		idx,
		obj.GetMessage(),
		obj.GetNetworkFlowInfo().GetProtocol(),
		obj.GetNetworkFlowInfo().GetSource().GetName(),
		obj.GetNetworkFlowInfo().GetSource().GetEntityType(),
		obj.GetNetworkFlowInfo().GetSource().GetDeploymentNamespace(),
		obj.GetNetworkFlowInfo().GetSource().GetDeploymentType(),
		obj.GetNetworkFlowInfo().GetSource().GetPort(),
		obj.GetNetworkFlowInfo().GetDestination().GetName(),
		obj.GetNetworkFlowInfo().GetDestination().GetEntityType(),
		obj.GetNetworkFlowInfo().GetDestination().GetDeploymentNamespace(),
		obj.GetNetworkFlowInfo().GetDestination().GetDeploymentType(),
		obj.GetNetworkFlowInfo().GetDestination().GetPort(),
		obj.GetType(),
		pgutils.NilOrTime(obj.GetTime()),
	}

	finalStr := "INSERT INTO alerts_Violations (alertid, idx, message, networkflowinfo_protocol, networkflowinfo_source_name, networkflowinfo_source_entitytype, networkflowinfo_source_deploymentnamespace, networkflowinfo_source_deploymenttype, networkflowinfo_source_port, networkflowinfo_destination_name, networkflowinfo_destination_entitytype, networkflowinfo_destination_deploymentnamespace, networkflowinfo_destination_deploymenttype, networkflowinfo_destination_port, type, time) VALUES($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16) ON CONFLICT(alertid, idx) DO UPDATE SET alertid = EXCLUDED.alertid, idx = EXCLUDED.idx, message = EXCLUDED.message, networkflowinfo_protocol = EXCLUDED.networkflowinfo_protocol, networkflowinfo_source_name = EXCLUDED.networkflowinfo_source_name, networkflowinfo_source_entitytype = EXCLUDED.networkflowinfo_source_entitytype, networkflowinfo_source_deploymentnamespace = EXCLUDED.networkflowinfo_source_deploymentnamespace, networkflowinfo_source_deploymenttype = EXCLUDED.networkflowinfo_source_deploymenttype, networkflowinfo_source_port = EXCLUDED.networkflowinfo_source_port, networkflowinfo_destination_name = EXCLUDED.networkflowinfo_destination_name, networkflowinfo_destination_entitytype = EXCLUDED.networkflowinfo_destination_entitytype, networkflowinfo_destination_deploymentnamespace = EXCLUDED.networkflowinfo_destination_deploymentnamespace, networkflowinfo_destination_deploymenttype = EXCLUDED.networkflowinfo_destination_deploymenttype, networkflowinfo_destination_port = EXCLUDED.networkflowinfo_destination_port, type = EXCLUDED.type, time = EXCLUDED.time"
	_, err := tx.Exec(ctx, finalStr, values...)
	if err != nil {
		return err
	}

	var query string

	for childIdx, child := range obj.GetKeyValueAttrs().GetAttrs() {
		if err := insertIntoAlertsViolationsAttrs(ctx, tx, child, alertid, idx, childIdx); err != nil {
			return err
		}
	}

	query = "delete from alerts_Violations_Attrs where alertid = $1 AND alert_violationidx = $2 AND idx >= $3"
	_, err = tx.Exec(ctx, query, alertid, idx, len(obj.GetKeyValueAttrs().GetAttrs()))
	if err != nil {
		return err
	}
	return nil
}

func insertIntoAlertsViolationsAttrs(ctx context.Context, tx pgx.Tx, obj *storage.Alert_Violation_KeyValueAttrs_KeyValueAttr, alertid string, alert_violationidx int, idx int) error {

	values := []interface{}{
		// parent primary keys start
		alertid,
		alert_violationidx,
		idx,
		obj.GetKey(),
		obj.GetValue(),
	}

	finalStr := "INSERT INTO alerts_Violations_Attrs (alertid, alert_violationidx, idx, key, value) VALUES($1, $2, $3, $4, $5) ON CONFLICT(alertid, alert_violationidx, idx) DO UPDATE SET alertid = EXCLUDED.alertid, alert_violationidx = EXCLUDED.alert_violationidx, idx = EXCLUDED.idx, key = EXCLUDED.key, value = EXCLUDED.value"
	_, err := tx.Exec(ctx, finalStr, values...)
	if err != nil {
		return err
	}

	return nil
}

func insertIntoAlertsProcesses(ctx context.Context, tx pgx.Tx, obj *storage.ProcessIndicator, alertid string, idx int) error {

	values := []interface{}{
		// parent primary keys start
		alertid,
		idx,
		obj.GetId(),
		obj.GetDeploymentId(),
		obj.GetContainerName(),
		obj.GetPodId(),
		obj.GetPodUid(),
		obj.GetSignal().GetId(),
		obj.GetSignal().GetContainerId(),
		pgutils.NilOrTime(obj.GetSignal().GetTime()),
		obj.GetSignal().GetName(),
		obj.GetSignal().GetArgs(),
		obj.GetSignal().GetExecFilePath(),
		obj.GetSignal().GetPid(),
		obj.GetSignal().GetUid(),
		obj.GetSignal().GetGid(),
		obj.GetSignal().GetLineage(),
		obj.GetSignal().GetScraped(),
		obj.GetClusterId(),
		obj.GetNamespace(),
		pgutils.NilOrTime(obj.GetContainerStartTime()),
		obj.GetImageId(),
	}

	finalStr := "INSERT INTO alerts_Processes (alertid, idx, id, deploymentid, containername, podid, poduid, signal_id, signal_containerid, signal_time, signal_name, signal_args, signal_execfilepath, signal_pid, signal_uid, signal_gid, signal_lineage, signal_scraped, clusterid, namespace, containerstarttime, imageid) VALUES($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16, $17, $18, $19, $20, $21, $22) ON CONFLICT(alertid, idx) DO UPDATE SET alertid = EXCLUDED.alertid, idx = EXCLUDED.idx, id = EXCLUDED.id, deploymentid = EXCLUDED.deploymentid, containername = EXCLUDED.containername, podid = EXCLUDED.podid, poduid = EXCLUDED.poduid, signal_id = EXCLUDED.signal_id, signal_containerid = EXCLUDED.signal_containerid, signal_time = EXCLUDED.signal_time, signal_name = EXCLUDED.signal_name, signal_args = EXCLUDED.signal_args, signal_execfilepath = EXCLUDED.signal_execfilepath, signal_pid = EXCLUDED.signal_pid, signal_uid = EXCLUDED.signal_uid, signal_gid = EXCLUDED.signal_gid, signal_lineage = EXCLUDED.signal_lineage, signal_scraped = EXCLUDED.signal_scraped, clusterid = EXCLUDED.clusterid, namespace = EXCLUDED.namespace, containerstarttime = EXCLUDED.containerstarttime, imageid = EXCLUDED.imageid"
	_, err := tx.Exec(ctx, finalStr, values...)
	if err != nil {
		return err
	}

	var query string

	for childIdx, child := range obj.GetSignal().GetLineageInfo() {
		if err := insertIntoAlertsProcessesLineageInfo(ctx, tx, child, alertid, idx, childIdx); err != nil {
			return err
		}
	}

	query = "delete from alerts_Processes_LineageInfo where alertid = $1 AND processindicatoridx = $2 AND idx >= $3"
	_, err = tx.Exec(ctx, query, alertid, idx, len(obj.GetSignal().GetLineageInfo()))
	if err != nil {
		return err
	}
	return nil
}

func insertIntoAlertsProcessesLineageInfo(ctx context.Context, tx pgx.Tx, obj *storage.ProcessSignal_LineageInfo, alertid string, processindicatoridx int, idx int) error {

	values := []interface{}{
		// parent primary keys start
		alertid,
		processindicatoridx,
		idx,
		obj.GetParentUid(),
		obj.GetParentExecFilePath(),
	}

	finalStr := "INSERT INTO alerts_Processes_LineageInfo (alertid, processindicatoridx, idx, parentuid, parentexecfilepath) VALUES($1, $2, $3, $4, $5) ON CONFLICT(alertid, processindicatoridx, idx) DO UPDATE SET alertid = EXCLUDED.alertid, processindicatoridx = EXCLUDED.processindicatoridx, idx = EXCLUDED.idx, parentuid = EXCLUDED.parentuid, parentexecfilepath = EXCLUDED.parentexecfilepath"
	_, err := tx.Exec(ctx, finalStr, values...)
	if err != nil {
		return err
	}

	return nil
}

func (s *storeImpl) copyFromAlerts(ctx context.Context, tx pgx.Tx, objs ...*storage.Alert) error {

	inputRows := [][]interface{}{}

	var err error

	// This is a copy so first we must delete the rows and re-add them
	// Which is essentially the desired behaviour of an upsert.
	var deletes []string

	copyCols := []string{

		"id",

		"policy_id",

		"policy_name",

		"policy_description",

		"policy_rationale",

		"policy_remediation",

		"policy_disabled",

		"policy_categories",

		"policy_lifecyclestages",

		"policy_eventsource",

		"policy_severity",

		"policy_enforcementactions",

		"policy_notifiers",

		"policy_lastupdated",

		"policy_sortname",

		"policy_sortlifecyclestage",

		"policy_sortenforcement",

		"policy_policyversion",

		"policy_criterialocked",

		"policy_mitrevectorslocked",

		"policy_isdefault",

		"lifecyclestage",

		"deployment_id",

		"deployment_name",

		"deployment_type",

		"deployment_namespace",

		"deployment_namespaceid",

		"deployment_labels",

		"deployment_clusterid",

		"deployment_clustername",

		"deployment_annotations",

		"deployment_inactive",

		"image_id",

		"image_name_registry",

		"image_name_remote",

		"image_name_tag",

		"image_name_fullname",

		"image_notpullable",

		"image_isclusterlocal",

		"resource_resourcetype",

		"resource_name",

		"resource_clusterid",

		"resource_clustername",

		"resource_namespace",

		"resource_namespaceid",

		"processviolation_message",

		"enforcement_action",

		"enforcement_message",

		"time",

		"firstoccurred",

		"resolvedat",

		"state",

		"snoozetill",

		"tags",

		"serialized",
	}

	for idx, obj := range objs {
		// Todo: ROX-9499 Figure out how to more cleanly template around this issue.
		log.Debugf("This is here for now because there is an issue with pods_TerminatedInstances where the obj in the loop is not used as it only consists of the parent id and the idx.  Putting this here as a stop gap to simply use the object.  %s", obj)

		serialized, marshalErr := obj.Marshal()
		if marshalErr != nil {
			return marshalErr
		}

		inputRows = append(inputRows, []interface{}{

			obj.GetId(),

			obj.GetPolicy().GetId(),

			obj.GetPolicy().GetName(),

			obj.GetPolicy().GetDescription(),

			obj.GetPolicy().GetRationale(),

			obj.GetPolicy().GetRemediation(),

			obj.GetPolicy().GetDisabled(),

			obj.GetPolicy().GetCategories(),

			obj.GetPolicy().GetLifecycleStages(),

			obj.GetPolicy().GetEventSource(),

			obj.GetPolicy().GetSeverity(),

			obj.GetPolicy().GetEnforcementActions(),

			obj.GetPolicy().GetNotifiers(),

			pgutils.NilOrTime(obj.GetPolicy().GetLastUpdated()),

			obj.GetPolicy().GetSORTName(),

			obj.GetPolicy().GetSORTLifecycleStage(),

			obj.GetPolicy().GetSORTEnforcement(),

			obj.GetPolicy().GetPolicyVersion(),

			obj.GetPolicy().GetCriteriaLocked(),

			obj.GetPolicy().GetMitreVectorsLocked(),

			obj.GetPolicy().GetIsDefault(),

			obj.GetLifecycleStage(),

			obj.GetDeployment().GetId(),

			obj.GetDeployment().GetName(),

			obj.GetDeployment().GetType(),

			obj.GetDeployment().GetNamespace(),

			obj.GetDeployment().GetNamespaceId(),

			obj.GetDeployment().GetLabels(),

			obj.GetDeployment().GetClusterId(),

			obj.GetDeployment().GetClusterName(),

			obj.GetDeployment().GetAnnotations(),

			obj.GetDeployment().GetInactive(),

			obj.GetImage().GetId(),

			obj.GetImage().GetName().GetRegistry(),

			obj.GetImage().GetName().GetRemote(),

			obj.GetImage().GetName().GetTag(),

			obj.GetImage().GetName().GetFullName(),

			obj.GetImage().GetNotPullable(),

			obj.GetImage().GetIsClusterLocal(),

			obj.GetResource().GetResourceType(),

			obj.GetResource().GetName(),

			obj.GetResource().GetClusterId(),

			obj.GetResource().GetClusterName(),

			obj.GetResource().GetNamespace(),

			obj.GetResource().GetNamespaceId(),

			obj.GetProcessViolation().GetMessage(),

			obj.GetEnforcement().GetAction(),

			obj.GetEnforcement().GetMessage(),

			pgutils.NilOrTime(obj.GetTime()),

			pgutils.NilOrTime(obj.GetFirstOccurred()),

			pgutils.NilOrTime(obj.GetResolvedAt()),

			obj.GetState(),

			pgutils.NilOrTime(obj.GetSnoozeTill()),

			obj.GetTags(),

			serialized,
		})

		// Add the id to be deleted.
		deletes = append(deletes, obj.GetId())

		// if we hit our batch size we need to push the data
		if (idx+1)%batchSize == 0 || idx == len(objs)-1 {
			// copy does not upsert so have to delete first.  parent deletion cascades so only need to
			// delete for the top level parent

			_, err = tx.Exec(ctx, deleteManyStmt, deletes)
			if err != nil {
				return err
			}
			// clear the inserts and vals for the next batch
			deletes = nil

			_, err = tx.CopyFrom(ctx, pgx.Identifier{"alerts"}, copyCols, pgx.CopyFromRows(inputRows))

			if err != nil {
				return err
			}

			// clear the input rows for the next batch
			inputRows = inputRows[:0]
		}
	}

	for _, obj := range objs {

		if err = s.copyFromAlertsWhitelists(ctx, tx, obj.GetId(), obj.GetPolicy().GetWhitelists()...); err != nil {
			return err
		}
		if err = s.copyFromAlertsExclusions(ctx, tx, obj.GetId(), obj.GetPolicy().GetExclusions()...); err != nil {
			return err
		}
		if err = s.copyFromAlertsScope(ctx, tx, obj.GetId(), obj.GetPolicy().GetScope()...); err != nil {
			return err
		}
		if err = s.copyFromAlertsPolicySections(ctx, tx, obj.GetId(), obj.GetPolicy().GetPolicySections()...); err != nil {
			return err
		}
		if err = s.copyFromAlertsMitreAttackVectors(ctx, tx, obj.GetId(), obj.GetPolicy().GetMitreAttackVectors()...); err != nil {
			return err
		}
		if err = s.copyFromAlertsContainers(ctx, tx, obj.GetId(), obj.GetDeployment().GetContainers()...); err != nil {
			return err
		}
		if err = s.copyFromAlertsViolations(ctx, tx, obj.GetId(), obj.GetViolations()...); err != nil {
			return err
		}
		if err = s.copyFromAlertsProcesses(ctx, tx, obj.GetId(), obj.GetProcessViolation().GetProcesses()...); err != nil {
			return err
		}
	}

	return err
}

func (s *storeImpl) copyFromAlertsWhitelists(ctx context.Context, tx pgx.Tx, alertid string, objs ...*storage.Exclusion) error {

	inputRows := [][]interface{}{}

	var err error

	copyCols := []string{

		"alertid",

		"idx",

		"name",

		"deployment_name",

		"deployment_scope_cluster",

		"deployment_scope_namespace",

		"deployment_scope_label_key",

		"deployment_scope_label_value",

		"image_name",

		"expiration",
	}

	for idx, obj := range objs {
		// Todo: ROX-9499 Figure out how to more cleanly template around this issue.
		log.Debugf("This is here for now because there is an issue with pods_TerminatedInstances where the obj in the loop is not used as it only consists of the parent id and the idx.  Putting this here as a stop gap to simply use the object.  %s", obj)

		inputRows = append(inputRows, []interface{}{

			alertid,

			idx,

			obj.GetName(),

			obj.GetDeployment().GetName(),

			obj.GetDeployment().GetScope().GetCluster(),

			obj.GetDeployment().GetScope().GetNamespace(),

			obj.GetDeployment().GetScope().GetLabel().GetKey(),

			obj.GetDeployment().GetScope().GetLabel().GetValue(),

			obj.GetImage().GetName(),

			pgutils.NilOrTime(obj.GetExpiration()),
		})

		// if we hit our batch size we need to push the data
		if (idx+1)%batchSize == 0 || idx == len(objs)-1 {
			// copy does not upsert so have to delete first.  parent deletion cascades so only need to
			// delete for the top level parent

			_, err = tx.CopyFrom(ctx, pgx.Identifier{"alerts_whitelists"}, copyCols, pgx.CopyFromRows(inputRows))

			if err != nil {
				return err
			}

			// clear the input rows for the next batch
			inputRows = inputRows[:0]
		}
	}

	return err
}

func (s *storeImpl) copyFromAlertsExclusions(ctx context.Context, tx pgx.Tx, alertid string, objs ...*storage.Exclusion) error {

	inputRows := [][]interface{}{}

	var err error

	copyCols := []string{

		"alertid",

		"idx",

		"name",

		"deployment_name",

		"deployment_scope_cluster",

		"deployment_scope_namespace",

		"deployment_scope_label_key",

		"deployment_scope_label_value",

		"image_name",

		"expiration",
	}

	for idx, obj := range objs {
		// Todo: ROX-9499 Figure out how to more cleanly template around this issue.
		log.Debugf("This is here for now because there is an issue with pods_TerminatedInstances where the obj in the loop is not used as it only consists of the parent id and the idx.  Putting this here as a stop gap to simply use the object.  %s", obj)

		inputRows = append(inputRows, []interface{}{

			alertid,

			idx,

			obj.GetName(),

			obj.GetDeployment().GetName(),

			obj.GetDeployment().GetScope().GetCluster(),

			obj.GetDeployment().GetScope().GetNamespace(),

			obj.GetDeployment().GetScope().GetLabel().GetKey(),

			obj.GetDeployment().GetScope().GetLabel().GetValue(),

			obj.GetImage().GetName(),

			pgutils.NilOrTime(obj.GetExpiration()),
		})

		// if we hit our batch size we need to push the data
		if (idx+1)%batchSize == 0 || idx == len(objs)-1 {
			// copy does not upsert so have to delete first.  parent deletion cascades so only need to
			// delete for the top level parent

			_, err = tx.CopyFrom(ctx, pgx.Identifier{"alerts_exclusions"}, copyCols, pgx.CopyFromRows(inputRows))

			if err != nil {
				return err
			}

			// clear the input rows for the next batch
			inputRows = inputRows[:0]
		}
	}

	return err
}

func (s *storeImpl) copyFromAlertsScope(ctx context.Context, tx pgx.Tx, alertid string, objs ...*storage.Scope) error {

	inputRows := [][]interface{}{}

	var err error

	copyCols := []string{

		"alertid",

		"idx",

		"cluster",

		"namespace",

		"label_key",

		"label_value",
	}

	for idx, obj := range objs {
		// Todo: ROX-9499 Figure out how to more cleanly template around this issue.
		log.Debugf("This is here for now because there is an issue with pods_TerminatedInstances where the obj in the loop is not used as it only consists of the parent id and the idx.  Putting this here as a stop gap to simply use the object.  %s", obj)

		inputRows = append(inputRows, []interface{}{

			alertid,

			idx,

			obj.GetCluster(),

			obj.GetNamespace(),

			obj.GetLabel().GetKey(),

			obj.GetLabel().GetValue(),
		})

		// if we hit our batch size we need to push the data
		if (idx+1)%batchSize == 0 || idx == len(objs)-1 {
			// copy does not upsert so have to delete first.  parent deletion cascades so only need to
			// delete for the top level parent

			_, err = tx.CopyFrom(ctx, pgx.Identifier{"alerts_scope"}, copyCols, pgx.CopyFromRows(inputRows))

			if err != nil {
				return err
			}

			// clear the input rows for the next batch
			inputRows = inputRows[:0]
		}
	}

	return err
}

func (s *storeImpl) copyFromAlertsPolicySections(ctx context.Context, tx pgx.Tx, alertid string, objs ...*storage.PolicySection) error {

	inputRows := [][]interface{}{}

	var err error

	copyCols := []string{

		"alertid",

		"idx",

		"sectionname",
	}

	for idx, obj := range objs {
		// Todo: ROX-9499 Figure out how to more cleanly template around this issue.
		log.Debugf("This is here for now because there is an issue with pods_TerminatedInstances where the obj in the loop is not used as it only consists of the parent id and the idx.  Putting this here as a stop gap to simply use the object.  %s", obj)

		inputRows = append(inputRows, []interface{}{

			alertid,

			idx,

			obj.GetSectionName(),
		})

		// if we hit our batch size we need to push the data
		if (idx+1)%batchSize == 0 || idx == len(objs)-1 {
			// copy does not upsert so have to delete first.  parent deletion cascades so only need to
			// delete for the top level parent

			_, err = tx.CopyFrom(ctx, pgx.Identifier{"alerts_policysections"}, copyCols, pgx.CopyFromRows(inputRows))

			if err != nil {
				return err
			}

			// clear the input rows for the next batch
			inputRows = inputRows[:0]
		}
	}

	for idx, obj := range objs {

		if err = s.copyFromAlertsPolicySectionsPolicyGroups(ctx, tx, alertid, idx, obj.GetPolicyGroups()...); err != nil {
			return err
		}
	}

	return err
}

func (s *storeImpl) copyFromAlertsPolicySectionsPolicyGroups(ctx context.Context, tx pgx.Tx, alertid string, policysectionidx int, objs ...*storage.PolicyGroup) error {

	inputRows := [][]interface{}{}

	var err error

	copyCols := []string{

		"alertid",

		"policysectionidx",

		"idx",

		"fieldname",

		"booleanoperator",

		"negate",
	}

	for idx, obj := range objs {
		// Todo: ROX-9499 Figure out how to more cleanly template around this issue.
		log.Debugf("This is here for now because there is an issue with pods_TerminatedInstances where the obj in the loop is not used as it only consists of the parent id and the idx.  Putting this here as a stop gap to simply use the object.  %s", obj)

		inputRows = append(inputRows, []interface{}{

			alertid,

			policysectionidx,

			idx,

			obj.GetFieldName(),

			obj.GetBooleanOperator(),

			obj.GetNegate(),
		})

		// if we hit our batch size we need to push the data
		if (idx+1)%batchSize == 0 || idx == len(objs)-1 {
			// copy does not upsert so have to delete first.  parent deletion cascades so only need to
			// delete for the top level parent

			_, err = tx.CopyFrom(ctx, pgx.Identifier{"alerts_policysections_policygroups"}, copyCols, pgx.CopyFromRows(inputRows))

			if err != nil {
				return err
			}

			// clear the input rows for the next batch
			inputRows = inputRows[:0]
		}
	}

	for idx, obj := range objs {

		if err = s.copyFromAlertsPolicySectionsPolicyGroupsValues(ctx, tx, alertid, policysectionidx, idx, obj.GetValues()...); err != nil {
			return err
		}
	}

	return err
}

func (s *storeImpl) copyFromAlertsPolicySectionsPolicyGroupsValues(ctx context.Context, tx pgx.Tx, alertid string, policysectionidx int, policygroupidx int, objs ...*storage.PolicyValue) error {

	inputRows := [][]interface{}{}

	var err error

	copyCols := []string{

		"alertid",

		"policysectionidx",

		"policygroupidx",

		"idx",

		"value",
	}

	for idx, obj := range objs {
		// Todo: ROX-9499 Figure out how to more cleanly template around this issue.
		log.Debugf("This is here for now because there is an issue with pods_TerminatedInstances where the obj in the loop is not used as it only consists of the parent id and the idx.  Putting this here as a stop gap to simply use the object.  %s", obj)

		inputRows = append(inputRows, []interface{}{

			alertid,

			policysectionidx,

			policygroupidx,

			idx,

			obj.GetValue(),
		})

		// if we hit our batch size we need to push the data
		if (idx+1)%batchSize == 0 || idx == len(objs)-1 {
			// copy does not upsert so have to delete first.  parent deletion cascades so only need to
			// delete for the top level parent

			_, err = tx.CopyFrom(ctx, pgx.Identifier{"alerts_policysections_policygroups_values"}, copyCols, pgx.CopyFromRows(inputRows))

			if err != nil {
				return err
			}

			// clear the input rows for the next batch
			inputRows = inputRows[:0]
		}
	}

	return err
}

func (s *storeImpl) copyFromAlertsMitreAttackVectors(ctx context.Context, tx pgx.Tx, alertid string, objs ...*storage.Policy_MitreAttackVectors) error {

	inputRows := [][]interface{}{}

	var err error

	copyCols := []string{

		"alertid",

		"idx",

		"tactic",

		"techniques",
	}

	for idx, obj := range objs {
		// Todo: ROX-9499 Figure out how to more cleanly template around this issue.
		log.Debugf("This is here for now because there is an issue with pods_TerminatedInstances where the obj in the loop is not used as it only consists of the parent id and the idx.  Putting this here as a stop gap to simply use the object.  %s", obj)

		inputRows = append(inputRows, []interface{}{

			alertid,

			idx,

			obj.GetTactic(),

			obj.GetTechniques(),
		})

		// if we hit our batch size we need to push the data
		if (idx+1)%batchSize == 0 || idx == len(objs)-1 {
			// copy does not upsert so have to delete first.  parent deletion cascades so only need to
			// delete for the top level parent

			_, err = tx.CopyFrom(ctx, pgx.Identifier{"alerts_mitreattackvectors"}, copyCols, pgx.CopyFromRows(inputRows))

			if err != nil {
				return err
			}

			// clear the input rows for the next batch
			inputRows = inputRows[:0]
		}
	}

	return err
}

func (s *storeImpl) copyFromAlertsContainers(ctx context.Context, tx pgx.Tx, alertid string, objs ...*storage.Alert_Deployment_Container) error {

	inputRows := [][]interface{}{}

	var err error

	copyCols := []string{

		"alertid",

		"idx",

		"image_id",

		"image_name_registry",

		"image_name_remote",

		"image_name_tag",

		"image_name_fullname",

		"image_notpullable",

		"image_isclusterlocal",

		"name",
	}

	for idx, obj := range objs {
		// Todo: ROX-9499 Figure out how to more cleanly template around this issue.
		log.Debugf("This is here for now because there is an issue with pods_TerminatedInstances where the obj in the loop is not used as it only consists of the parent id and the idx.  Putting this here as a stop gap to simply use the object.  %s", obj)

		inputRows = append(inputRows, []interface{}{

			alertid,

			idx,

			obj.GetImage().GetId(),

			obj.GetImage().GetName().GetRegistry(),

			obj.GetImage().GetName().GetRemote(),

			obj.GetImage().GetName().GetTag(),

			obj.GetImage().GetName().GetFullName(),

			obj.GetImage().GetNotPullable(),

			obj.GetImage().GetIsClusterLocal(),

			obj.GetName(),
		})

		// if we hit our batch size we need to push the data
		if (idx+1)%batchSize == 0 || idx == len(objs)-1 {
			// copy does not upsert so have to delete first.  parent deletion cascades so only need to
			// delete for the top level parent

			_, err = tx.CopyFrom(ctx, pgx.Identifier{"alerts_containers"}, copyCols, pgx.CopyFromRows(inputRows))

			if err != nil {
				return err
			}

			// clear the input rows for the next batch
			inputRows = inputRows[:0]
		}
	}

	return err
}

func (s *storeImpl) copyFromAlertsViolations(ctx context.Context, tx pgx.Tx, alertid string, objs ...*storage.Alert_Violation) error {

	inputRows := [][]interface{}{}

	var err error

	copyCols := []string{

		"alertid",

		"idx",

		"message",

		"networkflowinfo_protocol",

		"networkflowinfo_source_name",

		"networkflowinfo_source_entitytype",

		"networkflowinfo_source_deploymentnamespace",

		"networkflowinfo_source_deploymenttype",

		"networkflowinfo_source_port",

		"networkflowinfo_destination_name",

		"networkflowinfo_destination_entitytype",

		"networkflowinfo_destination_deploymentnamespace",

		"networkflowinfo_destination_deploymenttype",

		"networkflowinfo_destination_port",

		"type",

		"time",
	}

	for idx, obj := range objs {
		// Todo: ROX-9499 Figure out how to more cleanly template around this issue.
		log.Debugf("This is here for now because there is an issue with pods_TerminatedInstances where the obj in the loop is not used as it only consists of the parent id and the idx.  Putting this here as a stop gap to simply use the object.  %s", obj)

		inputRows = append(inputRows, []interface{}{

			alertid,

			idx,

			obj.GetMessage(),

			obj.GetNetworkFlowInfo().GetProtocol(),

			obj.GetNetworkFlowInfo().GetSource().GetName(),

			obj.GetNetworkFlowInfo().GetSource().GetEntityType(),

			obj.GetNetworkFlowInfo().GetSource().GetDeploymentNamespace(),

			obj.GetNetworkFlowInfo().GetSource().GetDeploymentType(),

			obj.GetNetworkFlowInfo().GetSource().GetPort(),

			obj.GetNetworkFlowInfo().GetDestination().GetName(),

			obj.GetNetworkFlowInfo().GetDestination().GetEntityType(),

			obj.GetNetworkFlowInfo().GetDestination().GetDeploymentNamespace(),

			obj.GetNetworkFlowInfo().GetDestination().GetDeploymentType(),

			obj.GetNetworkFlowInfo().GetDestination().GetPort(),

			obj.GetType(),

			pgutils.NilOrTime(obj.GetTime()),
		})

		// if we hit our batch size we need to push the data
		if (idx+1)%batchSize == 0 || idx == len(objs)-1 {
			// copy does not upsert so have to delete first.  parent deletion cascades so only need to
			// delete for the top level parent

			_, err = tx.CopyFrom(ctx, pgx.Identifier{"alerts_violations"}, copyCols, pgx.CopyFromRows(inputRows))

			if err != nil {
				return err
			}

			// clear the input rows for the next batch
			inputRows = inputRows[:0]
		}
	}

	for idx, obj := range objs {

		if err = s.copyFromAlertsViolationsAttrs(ctx, tx, alertid, idx, obj.GetKeyValueAttrs().GetAttrs()...); err != nil {
			return err
		}
	}

	return err
}

func (s *storeImpl) copyFromAlertsViolationsAttrs(ctx context.Context, tx pgx.Tx, alertid string, alert_violationidx int, objs ...*storage.Alert_Violation_KeyValueAttrs_KeyValueAttr) error {

	inputRows := [][]interface{}{}

	var err error

	copyCols := []string{

		"alertid",

		"alert_violationidx",

		"idx",

		"key",

		"value",
	}

	for idx, obj := range objs {
		// Todo: ROX-9499 Figure out how to more cleanly template around this issue.
		log.Debugf("This is here for now because there is an issue with pods_TerminatedInstances where the obj in the loop is not used as it only consists of the parent id and the idx.  Putting this here as a stop gap to simply use the object.  %s", obj)

		inputRows = append(inputRows, []interface{}{

			alertid,

			alert_violationidx,

			idx,

			obj.GetKey(),

			obj.GetValue(),
		})

		// if we hit our batch size we need to push the data
		if (idx+1)%batchSize == 0 || idx == len(objs)-1 {
			// copy does not upsert so have to delete first.  parent deletion cascades so only need to
			// delete for the top level parent

			_, err = tx.CopyFrom(ctx, pgx.Identifier{"alerts_violations_attrs"}, copyCols, pgx.CopyFromRows(inputRows))

			if err != nil {
				return err
			}

			// clear the input rows for the next batch
			inputRows = inputRows[:0]
		}
	}

	return err
}

func (s *storeImpl) copyFromAlertsProcesses(ctx context.Context, tx pgx.Tx, alertid string, objs ...*storage.ProcessIndicator) error {

	inputRows := [][]interface{}{}

	var err error

	copyCols := []string{

		"alertid",

		"idx",

		"id",

		"deploymentid",

		"containername",

		"podid",

		"poduid",

		"signal_id",

		"signal_containerid",

		"signal_time",

		"signal_name",

		"signal_args",

		"signal_execfilepath",

		"signal_pid",

		"signal_uid",

		"signal_gid",

		"signal_lineage",

		"signal_scraped",

		"clusterid",

		"namespace",

		"containerstarttime",

		"imageid",
	}

	for idx, obj := range objs {
		// Todo: ROX-9499 Figure out how to more cleanly template around this issue.
		log.Debugf("This is here for now because there is an issue with pods_TerminatedInstances where the obj in the loop is not used as it only consists of the parent id and the idx.  Putting this here as a stop gap to simply use the object.  %s", obj)

		inputRows = append(inputRows, []interface{}{

			alertid,

			idx,

			obj.GetId(),

			obj.GetDeploymentId(),

			obj.GetContainerName(),

			obj.GetPodId(),

			obj.GetPodUid(),

			obj.GetSignal().GetId(),

			obj.GetSignal().GetContainerId(),

			pgutils.NilOrTime(obj.GetSignal().GetTime()),

			obj.GetSignal().GetName(),

			obj.GetSignal().GetArgs(),

			obj.GetSignal().GetExecFilePath(),

			obj.GetSignal().GetPid(),

			obj.GetSignal().GetUid(),

			obj.GetSignal().GetGid(),

			obj.GetSignal().GetLineage(),

			obj.GetSignal().GetScraped(),

			obj.GetClusterId(),

			obj.GetNamespace(),

			pgutils.NilOrTime(obj.GetContainerStartTime()),

			obj.GetImageId(),
		})

		// if we hit our batch size we need to push the data
		if (idx+1)%batchSize == 0 || idx == len(objs)-1 {
			// copy does not upsert so have to delete first.  parent deletion cascades so only need to
			// delete for the top level parent

			_, err = tx.CopyFrom(ctx, pgx.Identifier{"alerts_processes"}, copyCols, pgx.CopyFromRows(inputRows))

			if err != nil {
				return err
			}

			// clear the input rows for the next batch
			inputRows = inputRows[:0]
		}
	}

	for idx, obj := range objs {

		if err = s.copyFromAlertsProcessesLineageInfo(ctx, tx, alertid, idx, obj.GetSignal().GetLineageInfo()...); err != nil {
			return err
		}
	}

	return err
}

func (s *storeImpl) copyFromAlertsProcessesLineageInfo(ctx context.Context, tx pgx.Tx, alertid string, processindicatoridx int, objs ...*storage.ProcessSignal_LineageInfo) error {

	inputRows := [][]interface{}{}

	var err error

	copyCols := []string{

		"alertid",

		"processindicatoridx",

		"idx",

		"parentuid",

		"parentexecfilepath",
	}

	for idx, obj := range objs {
		// Todo: ROX-9499 Figure out how to more cleanly template around this issue.
		log.Debugf("This is here for now because there is an issue with pods_TerminatedInstances where the obj in the loop is not used as it only consists of the parent id and the idx.  Putting this here as a stop gap to simply use the object.  %s", obj)

		inputRows = append(inputRows, []interface{}{

			alertid,

			processindicatoridx,

			idx,

			obj.GetParentUid(),

			obj.GetParentExecFilePath(),
		})

		// if we hit our batch size we need to push the data
		if (idx+1)%batchSize == 0 || idx == len(objs)-1 {
			// copy does not upsert so have to delete first.  parent deletion cascades so only need to
			// delete for the top level parent

			_, err = tx.CopyFrom(ctx, pgx.Identifier{"alerts_processes_lineageinfo"}, copyCols, pgx.CopyFromRows(inputRows))

			if err != nil {
				return err
			}

			// clear the input rows for the next batch
			inputRows = inputRows[:0]
		}
	}

	return err
}

// New returns a new Store instance using the provided sql instance.
func New(ctx context.Context, db *pgxpool.Pool) Store {
	createTableAlerts(ctx, db)

	return &storeImpl{
		db: db,
	}
}

func (s *storeImpl) copyFrom(ctx context.Context, objs ...*storage.Alert) error {
	conn, release := s.acquireConn(ctx, ops.Get, "Alert")
	defer release()

	tx, err := conn.Begin(ctx)
	if err != nil {
		return err
	}

	if err := s.copyFromAlerts(ctx, tx, objs...); err != nil {
		if err := tx.Rollback(ctx); err != nil {
			return err
		}
		return err
	}
	if err := tx.Commit(ctx); err != nil {
		return err
	}
	return nil
}

func (s *storeImpl) upsert(ctx context.Context, objs ...*storage.Alert) error {
	conn, release := s.acquireConn(ctx, ops.Get, "Alert")
	defer release()

	for _, obj := range objs {
		tx, err := conn.Begin(ctx)
		if err != nil {
			return err
		}

		if err := insertIntoAlerts(ctx, tx, obj); err != nil {
			if err := tx.Rollback(ctx); err != nil {
				return err
			}
			return err
		}
		if err := tx.Commit(ctx); err != nil {
			return err
		}
	}
	return nil
}

func (s *storeImpl) Upsert(ctx context.Context, obj *storage.Alert) error {
	defer metrics.SetPostgresOperationDurationTime(time.Now(), ops.Upsert, "Alert")

	return s.upsert(ctx, obj)
}

func (s *storeImpl) UpsertMany(ctx context.Context, objs []*storage.Alert) error {
	defer metrics.SetPostgresOperationDurationTime(time.Now(), ops.UpdateMany, "Alert")

	if len(objs) < batchAfter {
		return s.upsert(ctx, objs...)
	} else {
		return s.copyFrom(ctx, objs...)
	}
}

// Count returns the number of objects in the store
func (s *storeImpl) Count(ctx context.Context) (int, error) {
	defer metrics.SetPostgresOperationDurationTime(time.Now(), ops.Count, "Alert")

	row := s.db.QueryRow(ctx, countStmt)
	var count int
	if err := row.Scan(&count); err != nil {
		return 0, err
	}
	return count, nil
}

// Exists returns if the id exists in the store
func (s *storeImpl) Exists(ctx context.Context, id string) (bool, error) {
	defer metrics.SetPostgresOperationDurationTime(time.Now(), ops.Exists, "Alert")

	row := s.db.QueryRow(ctx, existsStmt, id)
	var exists bool
	if err := row.Scan(&exists); err != nil {
		return false, pgutils.ErrNilIfNoRows(err)
	}
	return exists, nil
}

// Get returns the object, if it exists from the store
func (s *storeImpl) Get(ctx context.Context, id string) (*storage.Alert, bool, error) {
	defer metrics.SetPostgresOperationDurationTime(time.Now(), ops.Get, "Alert")

	conn, release := s.acquireConn(ctx, ops.Get, "Alert")
	defer release()

	row := conn.QueryRow(ctx, getStmt, id)
	var data []byte
	if err := row.Scan(&data); err != nil {
		return nil, false, pgutils.ErrNilIfNoRows(err)
	}

	var msg storage.Alert
	if err := proto.Unmarshal(data, &msg); err != nil {
		return nil, false, err
	}
	return &msg, true, nil
}

func (s *storeImpl) acquireConn(ctx context.Context, op ops.Op, typ string) (*pgxpool.Conn, func()) {
	defer metrics.SetAcquireDBConnDuration(time.Now(), op, typ)
	conn, err := s.db.Acquire(ctx)
	if err != nil {
		panic(err)
	}
	return conn, conn.Release
}

// Delete removes the specified ID from the store
func (s *storeImpl) Delete(ctx context.Context, id string) error {
	defer metrics.SetPostgresOperationDurationTime(time.Now(), ops.Remove, "Alert")

	conn, release := s.acquireConn(ctx, ops.Remove, "Alert")
	defer release()

	if _, err := conn.Exec(ctx, deleteStmt, id); err != nil {
		return err
	}
	return nil
}

// GetIDs returns all the IDs for the store
func (s *storeImpl) GetIDs(ctx context.Context) ([]string, error) {
	defer metrics.SetPostgresOperationDurationTime(time.Now(), ops.GetAll, "storage.AlertIDs")

	rows, err := s.db.Query(ctx, getIDsStmt)
	if err != nil {
		return nil, pgutils.ErrNilIfNoRows(err)
	}
	defer rows.Close()
	var ids []string
	for rows.Next() {
		var id string
		if err := rows.Scan(&id); err != nil {
			return nil, err
		}
		ids = append(ids, id)
	}
	return ids, nil
}

// GetMany returns the objects specified by the IDs or the index in the missing indices slice
func (s *storeImpl) GetMany(ctx context.Context, ids []string) ([]*storage.Alert, []int, error) {
	defer metrics.SetPostgresOperationDurationTime(time.Now(), ops.GetMany, "Alert")

	conn, release := s.acquireConn(ctx, ops.GetMany, "Alert")
	defer release()

	rows, err := conn.Query(ctx, getManyStmt, ids)
	if err != nil {
		if err == pgx.ErrNoRows {
			missingIndices := make([]int, 0, len(ids))
			for i := range ids {
				missingIndices = append(missingIndices, i)
			}
			return nil, missingIndices, nil
		}
		return nil, nil, err
	}
	defer rows.Close()
	resultsByID := make(map[string]*storage.Alert)
	for rows.Next() {
		var data []byte
		if err := rows.Scan(&data); err != nil {
			return nil, nil, err
		}
		msg := &storage.Alert{}
		if err := proto.Unmarshal(data, msg); err != nil {
			return nil, nil, err
		}
		resultsByID[msg.GetId()] = msg
	}
	missingIndices := make([]int, 0, len(ids)-len(resultsByID))
	// It is important that the elems are populated in the same order as the input ids
	// slice, since some calling code relies on that to maintain order.
	elems := make([]*storage.Alert, 0, len(resultsByID))
	for i, id := range ids {
		if result, ok := resultsByID[id]; !ok {
			missingIndices = append(missingIndices, i)
		} else {
			elems = append(elems, result)
		}
	}
	return elems, missingIndices, nil
}

// Delete removes the specified IDs from the store
func (s *storeImpl) DeleteMany(ctx context.Context, ids []string) error {
	defer metrics.SetPostgresOperationDurationTime(time.Now(), ops.RemoveMany, "Alert")

	conn, release := s.acquireConn(ctx, ops.RemoveMany, "Alert")
	defer release()
	if _, err := conn.Exec(ctx, deleteManyStmt, ids); err != nil {
		return err
	}
	return nil
}

// Walk iterates over all of the objects in the store and applies the closure
func (s *storeImpl) Walk(ctx context.Context, fn func(obj *storage.Alert) error) error {
	rows, err := s.db.Query(ctx, walkStmt)
	if err != nil {
		return pgutils.ErrNilIfNoRows(err)
	}
	defer rows.Close()
	for rows.Next() {
		var data []byte
		if err := rows.Scan(&data); err != nil {
			return err
		}
		var msg storage.Alert
		if err := proto.Unmarshal(data, &msg); err != nil {
			return err
		}
		if err := fn(&msg); err != nil {
			return err
		}
	}
	return nil
}

//// Used for testing

func dropTableAlerts(ctx context.Context, db *pgxpool.Pool) {
	_, _ = db.Exec(ctx, "DROP TABLE IF EXISTS alerts CASCADE")
	dropTableAlertsWhitelists(ctx, db)
	dropTableAlertsExclusions(ctx, db)
	dropTableAlertsScope(ctx, db)
	dropTableAlertsPolicySections(ctx, db)
	dropTableAlertsMitreAttackVectors(ctx, db)
	dropTableAlertsContainers(ctx, db)
	dropTableAlertsViolations(ctx, db)
	dropTableAlertsProcesses(ctx, db)

}

func dropTableAlertsWhitelists(ctx context.Context, db *pgxpool.Pool) {
	_, _ = db.Exec(ctx, "DROP TABLE IF EXISTS alerts_Whitelists CASCADE")

}

func dropTableAlertsExclusions(ctx context.Context, db *pgxpool.Pool) {
	_, _ = db.Exec(ctx, "DROP TABLE IF EXISTS alerts_Exclusions CASCADE")

}

func dropTableAlertsScope(ctx context.Context, db *pgxpool.Pool) {
	_, _ = db.Exec(ctx, "DROP TABLE IF EXISTS alerts_Scope CASCADE")

}

func dropTableAlertsPolicySections(ctx context.Context, db *pgxpool.Pool) {
	_, _ = db.Exec(ctx, "DROP TABLE IF EXISTS alerts_PolicySections CASCADE")
	dropTableAlertsPolicySectionsPolicyGroups(ctx, db)

}

func dropTableAlertsPolicySectionsPolicyGroups(ctx context.Context, db *pgxpool.Pool) {
	_, _ = db.Exec(ctx, "DROP TABLE IF EXISTS alerts_PolicySections_PolicyGroups CASCADE")
	dropTableAlertsPolicySectionsPolicyGroupsValues(ctx, db)

}

func dropTableAlertsPolicySectionsPolicyGroupsValues(ctx context.Context, db *pgxpool.Pool) {
	_, _ = db.Exec(ctx, "DROP TABLE IF EXISTS alerts_PolicySections_PolicyGroups_Values CASCADE")

}

func dropTableAlertsMitreAttackVectors(ctx context.Context, db *pgxpool.Pool) {
	_, _ = db.Exec(ctx, "DROP TABLE IF EXISTS alerts_MitreAttackVectors CASCADE")

}

func dropTableAlertsContainers(ctx context.Context, db *pgxpool.Pool) {
	_, _ = db.Exec(ctx, "DROP TABLE IF EXISTS alerts_Containers CASCADE")

}

func dropTableAlertsViolations(ctx context.Context, db *pgxpool.Pool) {
	_, _ = db.Exec(ctx, "DROP TABLE IF EXISTS alerts_Violations CASCADE")
	dropTableAlertsViolationsAttrs(ctx, db)

}

func dropTableAlertsViolationsAttrs(ctx context.Context, db *pgxpool.Pool) {
	_, _ = db.Exec(ctx, "DROP TABLE IF EXISTS alerts_Violations_Attrs CASCADE")

}

func dropTableAlertsProcesses(ctx context.Context, db *pgxpool.Pool) {
	_, _ = db.Exec(ctx, "DROP TABLE IF EXISTS alerts_Processes CASCADE")
	dropTableAlertsProcessesLineageInfo(ctx, db)

}

func dropTableAlertsProcessesLineageInfo(ctx context.Context, db *pgxpool.Pool) {
	_, _ = db.Exec(ctx, "DROP TABLE IF EXISTS alerts_Processes_LineageInfo CASCADE")

}

func Destroy(ctx context.Context, db *pgxpool.Pool) {
	dropTableAlerts(ctx, db)
}

//// Stubs for satisfying legacy interfaces

// AckKeysIndexed acknowledges the passed keys were indexed
func (s *storeImpl) AckKeysIndexed(ctx context.Context, keys ...string) error {
	return nil
}

// GetKeysToIndex returns the keys that need to be indexed
func (s *storeImpl) GetKeysToIndex(ctx context.Context) ([]string, error) {
	return nil, nil
}
